{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deep Learning (RNN) Demo for Load Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEC 1: Import all the packages needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import random as rd\n",
    "import argparse\n",
    "import os, sys\n",
    "import csv\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEC 2: Load demand data from excel file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define class for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class County:\n",
    "    def __init__(self,parsename):\n",
    "        self.parsename = parsename\n",
    "        dataframe = xls.parse(parsename)\n",
    "        self.date = dataframe['Date']\n",
    "        self.hour = dataframe['Hr_End']\n",
    "        self.demand = dataframe['RT_Demand']\n",
    "        self.drybulb = dataframe['Dry_Bulb']\n",
    "        self.dewpnt = dataframe['Dew_Point']\n",
    "    def disp_all(self):\n",
    "        print self.dataframe\n",
    "    def get_all(self):\n",
    "        return self.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xls = pd.ExcelFile('smd_hourly.xls')\n",
    "INC = County('ISO NE CA')\n",
    "ME = County('ME')\n",
    "NH = County('NH')\n",
    "VT = County('VT')\n",
    "CT = County('CT')\n",
    "RI = County('RI')\n",
    "SEMA = County('SEMA')\n",
    "WCMA = County('WCMA')\n",
    "NEMA = County('NEMA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print INC.date[-8*24:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEC 3: setting all global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = './data/' # directory contains input data\n",
    "num_epoches = 50000 # training epoches for each customer samples\n",
    "day_steps = 24\n",
    "n_steps = day_steps # input size\n",
    "test_batch_size = 7*day_steps # days of a batch\n",
    "validation_batch_size = 0*day_steps\n",
    "train_batch_size = 7*day_steps\n",
    "feature_size = 1 # same time of a week\n",
    "n_hidden = 30 # input size\n",
    "num_layers = 3\n",
    "n_output = 1\n",
    "totalen = np.array(INC.demand).shape[0]\n",
    "decay = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEC 4: split dataset into training, cross-validation, and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concatenate data into database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5856, 1)\n",
      "(1, 5856, 1)\n"
     ]
    }
   ],
   "source": [
    "# DEMAND MATRIX 9 X LENGTH, 9: INC is total, index with 0, other substations are from 1 -> 8\n",
    "tmp = np.array(INC.demand)\n",
    "demand_mat = tmp.reshape([1,tmp.shape[0],1])\n",
    "demand_mat = demand_mat/25000\n",
    "#demand_mat = np.concatenate([demand_mat,np.array(ME.demand).reshape([1,np.array(ME.demand).shape[0],1])],axis = 0)\n",
    "#demand_mat = np.concatenate([demand_mat,np.array(NH.demand).reshape([1,np.array(NH.demand).shape[0],1])],axis = 0)\n",
    "#demand_mat = np.concatenate([demand_mat,np.array(VT.demand).reshape([1,np.array(VT.demand).shape[0],1])],axis = 0)\n",
    "#demand_mat = np.concatenate([demand_mat,np.array(CT.demand).reshape([1,np.array(CT.demand).shape[0],1])],axis = 0)\n",
    "#demand_mat = np.concatenate([demand_mat,np.array(RI.demand).reshape([1,np.array(RI.demand).shape[0],1])],axis = 0)\n",
    "#demand_mat = np.concatenate([demand_mat,np.array(SEMA.demand).reshape([1,np.array(SEMA.demand).shape[0],1])],axis = 0)\n",
    "#demand_mat = np.concatenate([demand_mat,np.array(WCMA.demand).reshape([1,np.array(WCMA.demand).shape[0],1])],axis = 0)\n",
    "#demand_mat = np.concatenate([demand_mat,np.array(NEMA.demand).reshape([1,np.array(NEMA.demand).shape[0],1])],axis = 0)\n",
    "print demand_mat.shape\n",
    "# DRY BULB MATRIX 9 X LENGTH, 9: INC is total, index with 0, other substations are from 1 -> 8\n",
    "tmp = np.array(INC.drybulb)\n",
    "drybulb_mat = tmp.reshape([1,tmp.shape[0],1])\n",
    "drybulb_mat = drybulb_mat/100\n",
    "#drybulb_mat = np.concatenate([drybulb_mat,np.array(ME.drybulb).reshape([1,np.array(ME.drybulb).shape[0],1])],axis = 0)\n",
    "#drybulb_mat = np.concatenate([drybulb_mat,np.array(NH.drybulb).reshape([1,np.array(NH.drybulb).shape[0],1])],axis = 0)\n",
    "#drybulb_mat = np.concatenate([drybulb_mat,np.array(VT.drybulb).reshape([1,np.array(VT.drybulb).shape[0],1])],axis = 0)\n",
    "#drybulb_mat = np.concatenate([drybulb_mat,np.array(CT.drybulb).reshape([1,np.array(CT.drybulb).shape[0],1])],axis = 0)\n",
    "#drybulb_mat = np.concatenate([drybulb_mat,np.array(RI.drybulb).reshape([1,np.array(RI.drybulb).shape[0],1])],axis = 0)\n",
    "#drybulb_mat = np.concatenate([drybulb_mat,np.array(SEMA.drybulb).reshape([1,np.array(SEMA.drybulb).shape[0],1])],axis = 0)\n",
    "#drybulb_mat = np.concatenate([drybulb_mat,np.array(WCMA.drybulb).reshape([1,np.array(WCMA.drybulb).shape[0],1])],axis = 0)\n",
    "#drybulb_mat = np.concatenate([drybulb_mat,np.array(NEMA.drybulb).reshape([1,np.array(NEMA.drybulb).shape[0],1])],axis = 0)\n",
    "#print drybulb_mat.shape\n",
    "# DEW PNT MATRIX 9 X LENGTH, 9: INC is total, index with 0, other substations are from 1 -> 8\n",
    "tmp = np.array(INC.dewpnt)\n",
    "dewpnt_mat = tmp.reshape([1,tmp.shape[0],1])\n",
    "dewpnt_mat = dewpnt_mat/100\n",
    "#dewpnt_mat = np.concatenate([dewpnt_mat,np.array(ME.dewpnt).reshape([1,np.array(ME.dewpnt).shape[0],1])],axis = 0)\n",
    "#dewpnt_mat = np.concatenate([dewpnt_mat,np.array(NH.dewpnt).reshape([1,np.array(NH.dewpnt).shape[0],1])],axis = 0)\n",
    "#dewpnt_mat = np.concatenate([dewpnt_mat,np.array(VT.dewpnt).reshape([1,np.array(VT.dewpnt).shape[0],1])],axis = 0)\n",
    "#dewpnt_mat = np.concatenate([dewpnt_mat,np.array(CT.dewpnt).reshape([1,np.array(CT.dewpnt).shape[0],1])],axis = 0)\n",
    "#dewpnt_mat = np.concatenate([dewpnt_mat,np.array(RI.dewpnt).reshape([1,np.array(RI.dewpnt).shape[0],1])],axis = 0)\n",
    "#dewpnt_mat = np.concatenate([dewpnt_mat,np.array(SEMA.dewpnt).reshape([1,np.array(SEMA.dewpnt).shape[0],1])],axis = 0)\n",
    "#dewpnt_mat = np.concatenate([dewpnt_mat,np.array(WCMA.dewpnt).reshape([1,np.array(WCMA.dewpnt).shape[0],1])],axis = 0)\n",
    "#dewpnt_mat = np.concatenate([dewpnt_mat,np.array(NEMA.dewpnt).reshape([1,np.array(NEMA.dewpnt).shape[0],1])],axis = 0)\n",
    "#print dewpnt_mat.shape\n",
    "\n",
    "#db = np.concatenate([demand_mat,dewpnt_mat,drybulb_mat],axis = 2)\n",
    "#db = np.concatenate([demand_mat,dewpnt_mat],axis = 2)\n",
    "db = demand_mat\n",
    "\n",
    "print db.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split into 3 parts using part array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#define id arrays\n",
    "test_id = np.array(test_batch_size)\n",
    "valid_id = np.array(validation_batch_size)\n",
    "train_id = np.array(totalen-test_batch_size-validation_batch_size-n_steps)\n",
    "\n",
    "#give values to id arrays\n",
    "rang = range(n_steps + decay,totalen-test_batch_size)\n",
    "valid_id = rd.sample(rang,validation_batch_size)\n",
    "test_id = np.array(range(totalen-test_batch_size,totalen))\n",
    "train_id = set(range(n_steps + decay,totalen-test_batch_size))-set(valid_id)\n",
    "\n",
    "#sort three id array\n",
    "valid_id = np.sort(valid_id)\n",
    "test_id = np.sort(test_id)\n",
    "train_id = np.array(list(train_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 4: define data generating function code. \n",
    "which generate a batch of batch-size large sequence data. the data is feature_size dims width and is a time series of float32 of steps steps. inputs and outputs are:\n",
    "\n",
    "inputs:\n",
    "----n_batch: number of samples in a batch\n",
    "----steps: the sequence length of a sample data\n",
    "----feature_size: dimensions of a single time step data frame\n",
    "\n",
    "outputs:\n",
    "----X inputs, shape(n_batch,steps,feature_size)\n",
    "----Y outputs should be, shape(n_batch,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_data_gen():\n",
    "    X = np.zeros((train_batch_size,n_steps,feature_size))\n",
    "    Y = np.zeros((train_batch_size,feature_size))\n",
    "    count = 0\n",
    "    rang = range(n_steps + decay,train_id.shape[0])\n",
    "    train_rd = rd.sample(rang,train_batch_size)\n",
    "    train_rd = np.sort(train_rd)\n",
    "    for i in train_rd:\n",
    "        Y[count] = db[:,i,:]\n",
    "        X[count] = db[:,i-n_steps-decay:i-decay,:]\n",
    "        count = count + 1\n",
    "    return (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def valid_data_gen():\n",
    "    X = np.zeros((train_batch_size,n_steps,feature_size))\n",
    "    Y = np.zeros((train_batch_size,feature_size))\n",
    "    count = 0\n",
    "    rang = range(n_steps + decay,valid_id.shape[0])\n",
    "    valid_rd = rd.sample(rang,train_batch_size)\n",
    "    valid_rd = np.sort(valid_rd)\n",
    "    for i in valid_rd:\n",
    "        Y[count] = db[:,i,:]\n",
    "        X[count] = db[:,i-n_steps-decay:i-decay,:]\n",
    "        count = count + 1\n",
    "    return (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_data_gen():\n",
    "    X = np.zeros((test_batch_size,n_steps,feature_size))\n",
    "    Y = np.zeros((test_batch_size,feature_size))\n",
    "    count = 0\n",
    "    for i in test_id:\n",
    "        Y[count] = db[:,i,:]\n",
    "        X[count] = db[:,i-n_steps-decay:i-decay,:]\n",
    "        count = count + 1\n",
    "    return (X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX = np.zeros((train_batch_size,n_steps,feature_size))\\nY = np.zeros((train_batch_size,feature_size))\\ncount = 0\\nrang = range(n_steps,train_id.shape[0])\\ntrain_rd = rd.sample(rang,train_batch_size)\\ntrain_rd = np.sort(train_rd)\\nfor i in train_id:\\n    Y[count] = db[:,i,:]\\n    X[count] = db[:,i-n_steps:i,:]\\n    count = count + 1\\n    if count == 3:\\n        break\\nprint Y\\nprint Y.shape\\nprint X\\nprint X.shape\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code testing\n",
    "\"\"\"\n",
    "(x,y) = test_data_gen()\n",
    "print x.shape\n",
    "x = x.reshape(test_batch_size,n_steps,feature_size)\n",
    "print x[0,:,:]\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "count = 0\n",
    "X = np.zeros((test_batch_size,n_steps,feature_size))\n",
    "Y = np.zeros((test_batch_size,feature_size))\n",
    "for i in test_id:\n",
    "    print i\n",
    "    Y[0] = db[:,i,:]\n",
    "    X[0] = db[:,i-n_steps:i,:]\n",
    "    count = count + 1\n",
    "    if count == 3:\n",
    "        break\n",
    "print Y\n",
    "print Y.shape\n",
    "print X\n",
    "print X.shape\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "X = np.zeros((train_batch_size,n_steps,feature_size))\n",
    "Y = np.zeros((train_batch_size,feature_size))\n",
    "count = 0\n",
    "rang = range(n_steps,train_id.shape[0])\n",
    "train_rd = rd.sample(rang,train_batch_size)\n",
    "train_rd = np.sort(train_rd)\n",
    "for i in train_id:\n",
    "    Y[count] = db[:,i,:]\n",
    "    X[count] = db[:,i-n_steps:i,:]\n",
    "    count = count + 1\n",
    "    if count == 3:\n",
    "        break\n",
    "print Y\n",
    "print Y.shape\n",
    "print X\n",
    "print X.shape\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: construct RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.BasicLSTMCell object at 0x7ffb58eb5d10>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    }
   ],
   "source": [
    "# create placeholder for x and y\n",
    "#with tf.device('/gpu:0'):\n",
    "x = tf.placeholder(\"float\",[None,n_steps,feature_size])\n",
    "istate = tf.placeholder(\"float\",[None,num_layers*2*n_hidden])\n",
    "y = tf.placeholder(\"float\",[None,n_output])\n",
    "\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([feature_size, n_hidden])), # Hidden layer weights\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_output]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([n_output]))\n",
    "}\n",
    "def RNN(_X, _istate, _weights, _biases):\n",
    "    # input shape: (batch_size, n_steps, n_input)\n",
    "    _X = tf.transpose(_X, [1, 0, 2])  # permute n_steps and batch_size\n",
    "    # Reshape to prepare input to hidden activation\n",
    "    _X = tf.reshape(_X, [-1, feature_size]) # (n_steps*batch_size, n_input)\n",
    "    # Linear activation\n",
    "    _X = tf.matmul(_X, _weights['hidden']) + _biases['hidden']\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "    stacked_lstm_cell = tf.nn.rnn_cell.MultiRNNCell([lstm_cell]*num_layers)\n",
    "\n",
    "    # Split data because rnn cell needs a list of inputs for the RNN inner loop\n",
    "    _X = tf.split(0, n_steps, _X) # n_steps * (batch_size, n_hidden)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = tf.nn.rnn(stacked_lstm_cell, _X, initial_state=_istate)\n",
    "\n",
    "    # Linear activation\n",
    "    # Get inner loop last output\n",
    "    return tf.matmul(outputs[-1], _weights['out']) + _biases['out']\n",
    "\n",
    "pred = RNN(x, istate, weights, biases)\n",
    "#cost function \n",
    "cost = tf.reduce_mean(tf.pow(pred[:,0]-y[:,0],2)) # cost function of this batch of data\n",
    "#compute parameter updates\n",
    "#optimizer = tf.train.GradientDescentOptimizer(0.2).minimize(cost)\n",
    "optimizer = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxe(predictions, targets):\n",
    "    return max(abs(predictions-targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mape(predictions, targets):\n",
    "    return np.mean(abs(predictions-targets)/targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "outlist = np.zeros([(num_epoches/10),test_batch_size])\n",
    "kind = 0\n",
    "time1 = time.time()\n",
    "# generate test data\n",
    "test_x,test_y = test_data_gen()\n",
    "test_x = test_x.reshape(test_batch_size,n_steps,feature_size)\n",
    "### Execute\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 ---- Process: 0.00Train = 0.223085\n",
      "Iter 10 ---- Process: 0.02Train = 0.0353952\n",
      "Iter 20 ---- Process: 0.04Train = 0.265133\n",
      "Iter 30 ---- Process: 0.06Train = 0.156453\n",
      "Iter 40 ---- Process: 0.08Train = 0.0501862\n",
      "Iter 50 ---- Process: 0.10Train = 0.134683\n",
      "Iter 60 ---- Process: 0.12Train = 0.118493\n",
      "Iter 70 ---- Process: 0.14Train = 0.0440657\n",
      "Iter 80 ---- Process: 0.16Train = 0.0355525\n",
      "Iter 90 ---- Process: 0.18Train = 0.101426\n",
      "Iter 100 ---- Process: 0.20Train = 0.0209369\n",
      "Iter 110 ---- Process: 0.22Train = 0.0217541\n",
      "Iter 120 ---- Process: 0.24Train = 0.0458892\n",
      "Iter 130 ---- Process: 0.26Train = 0.0306531\n",
      "Iter 140 ---- Process: 0.28Train = 0.0160737\n",
      "Iter 150 ---- Process: 0.30Train = 0.0226126\n",
      "Iter 160 ---- Process: 0.32Train = 0.0165444\n",
      "Iter 170 ---- Process: 0.34Train = 0.0144947\n",
      "Iter 180 ---- Process: 0.36Train = 0.056217\n",
      "Iter 190 ---- Process: 0.38Train = 0.0197439\n",
      "Iter 200 ---- Process: 0.40Train = 0.0790837\n",
      "Iter 210 ---- Process: 0.42Train = 0.0362876\n",
      "Iter 220 ---- Process: 0.44Train = 0.0391101\n",
      "Iter 230 ---- Process: 0.46Train = 0.0718506\n",
      "Iter 240 ---- Process: 0.48Train = 0.0131562\n",
      "Iter 250 ---- Process: 0.50Train = 0.0499782\n",
      "Iter 260 ---- Process: 0.52Train = 0.0678367\n",
      "Iter 270 ---- Process: 0.54Train = 0.0102295\n",
      "Iter 280 ---- Process: 0.56Train = 0.0325876\n",
      "Iter 290 ---- Process: 0.58Train = 0.0356992\n",
      "Iter 300 ---- Process: 0.60Train = 0.0228273\n",
      "Iter 310 ---- Process: 0.62Train = 0.0133552\n",
      "Iter 320 ---- Process: 0.64Train = 0.0264383\n",
      "Iter 330 ---- Process: 0.66Train = 0.0286366\n",
      "Iter 340 ---- Process: 0.68Train = 0.019399\n",
      "Iter 350 ---- Process: 0.70Train = 0.0129286\n",
      "Iter 360 ---- Process: 0.72Train = 0.0169977\n",
      "Iter 370 ---- Process: 0.74Train = 0.019775\n",
      "Iter 380 ---- Process: 0.76Train = 0.0254603\n",
      "Iter 390 ---- Process: 0.78Train = 0.0240819\n",
      "Iter 400 ---- Process: 0.80Train = 0.0184237\n",
      "Iter 410 ---- Process: 0.82Train = 0.00486328\n",
      "Iter 420 ---- Process: 0.84Train = 0.0205691\n",
      "Iter 430 ---- Process: 0.86Train = 0.00892215\n",
      "Iter 440 ---- Process: 0.88Train = 0.0116691\n",
      "Iter 450 ---- Process: 0.90Train = 0.0144116\n",
      "Iter 460 ---- Process: 0.92Train = 0.0127188\n",
      "Iter 470 ---- Process: 0.94Train = 0.00871006\n",
      "Iter 480 ---- Process: 0.96Train = 0.00762446\n",
      "Iter 490 ---- Process: 0.98Train = 0.0104523\n",
      "Iter 500 ---- Process: 1.00Train = 0.00946828\n",
      "Iter 510 ---- Process: 1.02Train = 0.0134093\n",
      "Iter 520 ---- Process: 1.04Train = 0.00955104\n",
      "Iter 530 ---- Process: 1.06Train = 0.00914267\n",
      "Iter 540 ---- Process: 1.08Train = 0.0109491\n",
      "Iter 550 ---- Process: 1.10Train = 0.0122677\n",
      "Iter 560 ---- Process: 1.12Train = 0.0115451\n",
      "Iter 570 ---- Process: 1.14Train = 0.0104074\n",
      "Iter 580 ---- Process: 1.16Train = 0.0152124\n",
      "Iter 590 ---- Process: 1.18Train = 0.0163621\n",
      "Iter 600 ---- Process: 1.20Train = 0.00975091\n",
      "Iter 610 ---- Process: 1.22Train = 0.00480586\n",
      "Iter 620 ---- Process: 1.24Train = 0.0114185\n",
      "Iter 630 ---- Process: 1.26Train = 0.00665839\n",
      "Iter 640 ---- Process: 1.28Train = 0.01224\n",
      "Iter 650 ---- Process: 1.30Train = 0.00689523\n",
      "Iter 660 ---- Process: 1.32Train = 0.00472533\n",
      "Iter 670 ---- Process: 1.34Train = 0.00591618\n",
      "Iter 680 ---- Process: 1.36Train = 0.00399723\n",
      "Iter 690 ---- Process: 1.38Train = 0.00886814\n",
      "Iter 700 ---- Process: 1.40Train = 0.00698806\n",
      "Iter 710 ---- Process: 1.42Train = 0.00741603\n",
      "Iter 720 ---- Process: 1.44Train = 0.0048911\n",
      "Iter 730 ---- Process: 1.46Train = 0.0087238\n",
      "Iter 740 ---- Process: 1.48Train = 0.0105618\n",
      "Iter 750 ---- Process: 1.50Train = 0.00440701\n",
      "Iter 760 ---- Process: 1.52Train = 0.00503801\n",
      "Iter 770 ---- Process: 1.54Train = 0.00984586\n",
      "Iter 780 ---- Process: 1.56Train = 0.00429313\n",
      "Iter 790 ---- Process: 1.58Train = 0.00480489\n",
      "Iter 800 ---- Process: 1.60Train = 0.00705367\n",
      "Iter 810 ---- Process: 1.62Train = 0.00941797\n",
      "Iter 820 ---- Process: 1.64Train = 0.00375894\n",
      "Iter 830 ---- Process: 1.66Train = 0.00660623\n",
      "Iter 840 ---- Process: 1.68Train = 0.00454982\n",
      "Iter 850 ---- Process: 1.70Train = 0.00319906\n",
      "Iter 860 ---- Process: 1.72Train = 0.00550649\n",
      "Iter 870 ---- Process: 1.74Train = 0.00998055\n",
      "Iter 880 ---- Process: 1.76Train = 0.00635449\n",
      "Iter 890 ---- Process: 1.78Train = 0.0056135\n",
      "Iter 900 ---- Process: 1.80Train = 0.00556626\n",
      "Iter 910 ---- Process: 1.82Train = 0.00258214\n",
      "Iter 920 ---- Process: 1.84Train = 0.00348193\n",
      "Iter 930 ---- Process: 1.86Train = 0.00328388\n",
      "Iter 940 ---- Process: 1.88Train = 0.00323419\n",
      "Iter 950 ---- Process: 1.90Train = 0.00357898\n",
      "Iter 960 ---- Process: 1.92Train = 0.00489931\n",
      "Iter 970 ---- Process: 1.94Train = 0.00295683\n",
      "Iter 980 ---- Process: 1.96Train = 0.00307922\n",
      "Iter 990 ---- Process: 1.98Train = 0.00333343\n",
      "Iter 1000 ---- Process: 2.00Train = 0.00738212\n",
      "Iter 1010 ---- Process: 2.02Train = 0.00393306\n",
      "Iter 1020 ---- Process: 2.04Train = 0.00578794\n",
      "Iter 1030 ---- Process: 2.06Train = 0.00372657\n",
      "Iter 1040 ---- Process: 2.08Train = 0.00329863\n",
      "Iter 1050 ---- Process: 2.10Train = 0.00522745\n",
      "Iter 1060 ---- Process: 2.12Train = 0.00342658\n",
      "Iter 1070 ---- Process: 2.14Train = 0.00312889\n",
      "Iter 1080 ---- Process: 2.16Train = 0.00278661\n",
      "Iter 1090 ---- Process: 2.18Train = 0.00541674\n",
      "Iter 1100 ---- Process: 2.20Train = 0.00477837\n",
      "Iter 1110 ---- Process: 2.22Train = 0.00477708\n",
      "Iter 1120 ---- Process: 2.24Train = 0.00467121\n",
      "Iter 1130 ---- Process: 2.26Train = 0.00187704\n",
      "Iter 1140 ---- Process: 2.28Train = 0.00461209\n",
      "Iter 1150 ---- Process: 2.30Train = 0.00366393\n",
      "Iter 1160 ---- Process: 2.32Train = 0.00354924\n",
      "Iter 1170 ---- Process: 2.34Train = 0.00344129\n",
      "Iter 1180 ---- Process: 2.36Train = 0.00453166\n",
      "Iter 1190 ---- Process: 2.38Train = 0.00269199\n",
      "Iter 1200 ---- Process: 2.40Train = 0.00313743\n",
      "Iter 1210 ---- Process: 2.42Train = 0.00224633\n",
      "Iter 1220 ---- Process: 2.44Train = 0.00365307\n",
      "Iter 1230 ---- Process: 2.46Train = 0.00370022\n",
      "Iter 1240 ---- Process: 2.48Train = 0.00429424\n",
      "Iter 1250 ---- Process: 2.50Train = 0.00194989\n",
      "Iter 1260 ---- Process: 2.52Train = 0.00351537\n",
      "Iter 1270 ---- Process: 2.54Train = 0.00519703\n",
      "Iter 1280 ---- Process: 2.56Train = 0.00326797\n",
      "Iter 1290 ---- Process: 2.58Train = 0.00373383\n",
      "Iter 1300 ---- Process: 2.60Train = 0.00394268\n",
      "Iter 1310 ---- Process: 2.62Train = 0.00300532\n",
      "Iter 1320 ---- Process: 2.64Train = 0.00323998\n",
      "Iter 1330 ---- Process: 2.66Train = 0.0017447\n",
      "Iter 1340 ---- Process: 2.68Train = 0.00509994\n",
      "Iter 1350 ---- Process: 2.70Train = 0.00314798\n",
      "Iter 1360 ---- Process: 2.72Train = 0.00205017\n",
      "Iter 1370 ---- Process: 2.74Train = 0.00184816\n",
      "Iter 1380 ---- Process: 2.76Train = 0.00363458\n",
      "Iter 1390 ---- Process: 2.78Train = 0.0033511\n",
      "Iter 1400 ---- Process: 2.80Train = 0.00179403\n",
      "Iter 1410 ---- Process: 2.82Train = 0.00361396\n",
      "Iter 1420 ---- Process: 2.84Train = 0.00197621\n",
      "Iter 1430 ---- Process: 2.86Train = 0.00184592\n",
      "Iter 1440 ---- Process: 2.88Train = 0.00224699\n",
      "Iter 1450 ---- Process: 2.90Train = 0.00147075\n",
      "Iter 1460 ---- Process: 2.92Train = 0.00247243\n",
      "Iter 1470 ---- Process: 2.94Train = 0.0013344\n",
      "Iter 1480 ---- Process: 2.96Train = 0.00605094\n",
      "Iter 1490 ---- Process: 2.98Train = 0.00269219\n",
      "Iter 1500 ---- Process: 3.00Train = 0.0025567\n",
      "Iter 1510 ---- Process: 3.02Train = 0.00241822\n",
      "Iter 1520 ---- Process: 3.04Train = 0.00245464\n",
      "Iter 1530 ---- Process: 3.06Train = 0.00270307\n",
      "Iter 1540 ---- Process: 3.08Train = 0.0022799\n",
      "Iter 1550 ---- Process: 3.10Train = 0.0018897\n",
      "Iter 1560 ---- Process: 3.12Train = 0.00176948\n",
      "Iter 1570 ---- Process: 3.14Train = 0.00266291\n",
      "Iter 1580 ---- Process: 3.16Train = 0.00446742\n",
      "Iter 1590 ---- Process: 3.18Train = 0.00331538\n",
      "Iter 1600 ---- Process: 3.20Train = 0.000653662\n",
      "Iter 1610 ---- Process: 3.22Train = 0.00428172\n",
      "Iter 1620 ---- Process: 3.24Train = 0.00384797\n",
      "Iter 1630 ---- Process: 3.26Train = 0.00240539\n",
      "Iter 1640 ---- Process: 3.28Train = 0.0024214\n",
      "Iter 1650 ---- Process: 3.30Train = 0.0028566\n",
      "Iter 1660 ---- Process: 3.32Train = 0.0024598\n",
      "Iter 1670 ---- Process: 3.34Train = 0.00163438\n",
      "Iter 1680 ---- Process: 3.36Train = 0.00326584\n",
      "Iter 1690 ---- Process: 3.38Train = 0.00227519\n",
      "Iter 1700 ---- Process: 3.40Train = 0.00276069\n",
      "Iter 1710 ---- Process: 3.42Train = 0.00287169\n",
      "Iter 1720 ---- Process: 3.44Train = 0.00233261\n",
      "Iter 1730 ---- Process: 3.46Train = 0.00280351\n",
      "Iter 1740 ---- Process: 3.48Train = 0.00155136\n",
      "Iter 1750 ---- Process: 3.50Train = 0.00327844\n",
      "Iter 1760 ---- Process: 3.52Train = 0.00141163\n",
      "Iter 1770 ---- Process: 3.54Train = 0.00142219\n",
      "Iter 1780 ---- Process: 3.56Train = 0.0014023\n",
      "Iter 1790 ---- Process: 3.58Train = 0.00138958\n",
      "Iter 1800 ---- Process: 3.60Train = 0.00224436\n",
      "Iter 1810 ---- Process: 3.62Train = 0.00174399\n",
      "Iter 1820 ---- Process: 3.64Train = 0.00154386\n",
      "Iter 1830 ---- Process: 3.66Train = 0.00327678\n",
      "Iter 1840 ---- Process: 3.68Train = 0.00117669\n",
      "Iter 1850 ---- Process: 3.70Train = 0.00353935\n",
      "Iter 1860 ---- Process: 3.72Train = 0.00194662\n",
      "Iter 1870 ---- Process: 3.74Train = 0.00149401\n",
      "Iter 1880 ---- Process: 3.76Train = 0.00185485\n",
      "Iter 1890 ---- Process: 3.78Train = 0.00381756\n",
      "Iter 1900 ---- Process: 3.80Train = 0.00229147\n",
      "Iter 1910 ---- Process: 3.82Train = 0.000925767\n",
      "Iter 1920 ---- Process: 3.84Train = 0.00256087\n",
      "Iter 1930 ---- Process: 3.86Train = 0.00188077\n",
      "Iter 1940 ---- Process: 3.88Train = 0.00148907\n",
      "Iter 1950 ---- Process: 3.90Train = 0.0011367\n",
      "Iter 1960 ---- Process: 3.92Train = 0.00427909\n",
      "Iter 1970 ---- Process: 3.94Train = 0.00155284\n",
      "Iter 1980 ---- Process: 3.96Train = 0.00198574\n",
      "Iter 1990 ---- Process: 3.98Train = 0.00167484\n",
      "Iter 2000 ---- Process: 4.00Train = 0.00281752\n",
      "Iter 2010 ---- Process: 4.02Train = 0.00215388\n",
      "Iter 2020 ---- Process: 4.04Train = 0.000916681\n",
      "Iter 2030 ---- Process: 4.06Train = 0.00127274\n",
      "Iter 2040 ---- Process: 4.08Train = 0.00296652\n",
      "Iter 2050 ---- Process: 4.10Train = 0.00245389\n",
      "Iter 2060 ---- Process: 4.12Train = 0.0025659\n",
      "Iter 2070 ---- Process: 4.14Train = 0.0019025\n",
      "Iter 2080 ---- Process: 4.16Train = 0.00273968\n",
      "Iter 2090 ---- Process: 4.18Train = 0.0023278\n",
      "Iter 2100 ---- Process: 4.20Train = 0.00262499\n",
      "Iter 2110 ---- Process: 4.22Train = 0.00201071\n",
      "Iter 2120 ---- Process: 4.24Train = 0.00164054\n",
      "Iter 2130 ---- Process: 4.26Train = 0.00159494\n",
      "Iter 2140 ---- Process: 4.28Train = 0.00135084\n",
      "Iter 2150 ---- Process: 4.30Train = 0.00176196\n",
      "Iter 2160 ---- Process: 4.32Train = 0.00210756\n",
      "Iter 2170 ---- Process: 4.34Train = 0.000821504\n",
      "Iter 2180 ---- Process: 4.36Train = 0.00150125\n",
      "Iter 2190 ---- Process: 4.38Train = 0.00147863\n",
      "Iter 2200 ---- Process: 4.40Train = 0.00160643\n",
      "Iter 2210 ---- Process: 4.42Train = 0.00122765\n",
      "Iter 2220 ---- Process: 4.44Train = 0.00275809\n",
      "Iter 2230 ---- Process: 4.46Train = 0.00133304\n",
      "Iter 2240 ---- Process: 4.48Train = 0.00178044\n",
      "Iter 2250 ---- Process: 4.50Train = 0.00192958\n",
      "Iter 2260 ---- Process: 4.52Train = 0.0015814\n",
      "Iter 2270 ---- Process: 4.54Train = 0.00140332\n",
      "Iter 2280 ---- Process: 4.56Train = 0.00245777\n",
      "Iter 2290 ---- Process: 4.58Train = 0.00142118\n",
      "Iter 2300 ---- Process: 4.60Train = 0.00156524\n",
      "Iter 2310 ---- Process: 4.62Train = 0.00134445\n",
      "Iter 2320 ---- Process: 4.64Train = 0.00143173\n",
      "Iter 2330 ---- Process: 4.66Train = 0.000854168\n",
      "Iter 2340 ---- Process: 4.68Train = 0.00163082\n",
      "Iter 2350 ---- Process: 4.70Train = 0.00126498\n",
      "Iter 2360 ---- Process: 4.72Train = 0.00166814\n",
      "Iter 2370 ---- Process: 4.74Train = 0.00142789\n",
      "Iter 2380 ---- Process: 4.76Train = 0.00190531\n",
      "Iter 2390 ---- Process: 4.78Train = 0.00121984\n",
      "Iter 2400 ---- Process: 4.80Train = 0.00127199\n",
      "Iter 2410 ---- Process: 4.82Train = 0.00197136\n",
      "Iter 2420 ---- Process: 4.84Train = 0.0010906\n",
      "Iter 2430 ---- Process: 4.86Train = 0.00121492\n",
      "Iter 2440 ---- Process: 4.88Train = 0.00204479\n",
      "Iter 2450 ---- Process: 4.90Train = 0.0022285\n",
      "Iter 2460 ---- Process: 4.92Train = 0.000943282\n",
      "Iter 2470 ---- Process: 4.94Train = 0.000707082\n",
      "Iter 2480 ---- Process: 4.96Train = 0.00134483\n",
      "Iter 2490 ---- Process: 4.98Train = 0.0018584\n",
      "Iter 2500 ---- Process: 5.00Train = 0.000747382\n",
      "Iter 2510 ---- Process: 5.02Train = 0.00123579\n",
      "Iter 2520 ---- Process: 5.04Train = 0.00153155\n",
      "Iter 2530 ---- Process: 5.06Train = 0.00118787\n",
      "Iter 2540 ---- Process: 5.08Train = 0.00135747\n",
      "Iter 2550 ---- Process: 5.10Train = 0.00202388\n",
      "Iter 2560 ---- Process: 5.12Train = 0.00162458\n",
      "Iter 2570 ---- Process: 5.14Train = 0.000972556\n",
      "Iter 2580 ---- Process: 5.16Train = 0.000910227\n",
      "Iter 2590 ---- Process: 5.18Train = 0.00175519\n",
      "Iter 2600 ---- Process: 5.20Train = 0.00159318\n",
      "Iter 2610 ---- Process: 5.22Train = 0.00104861\n",
      "Iter 2620 ---- Process: 5.24Train = 0.00107799\n",
      "Iter 2630 ---- Process: 5.26Train = 0.00147742\n",
      "Iter 2640 ---- Process: 5.28Train = 0.00136466\n",
      "Iter 2650 ---- Process: 5.30Train = 0.00133582\n",
      "Iter 2660 ---- Process: 5.32Train = 0.00142319\n",
      "Iter 2670 ---- Process: 5.34Train = 0.00130821\n",
      "Iter 2680 ---- Process: 5.36Train = 0.00165544\n",
      "Iter 2690 ---- Process: 5.38Train = 0.00126556\n",
      "Iter 2700 ---- Process: 5.40Train = 0.00184524\n",
      "Iter 2710 ---- Process: 5.42Train = 0.00125461\n",
      "Iter 2720 ---- Process: 5.44Train = 0.00130939\n",
      "Iter 2730 ---- Process: 5.46Train = 0.000999236\n",
      "Iter 2740 ---- Process: 5.48Train = 0.000733774\n",
      "Iter 2750 ---- Process: 5.50Train = 0.000713473\n",
      "Iter 2760 ---- Process: 5.52Train = 0.00155113\n",
      "Iter 2770 ---- Process: 5.54Train = 0.00115852\n",
      "Iter 2780 ---- Process: 5.56Train = 0.00160641\n",
      "Iter 2790 ---- Process: 5.58Train = 0.00140976\n",
      "Iter 2800 ---- Process: 5.60Train = 0.00140965\n",
      "Iter 2810 ---- Process: 5.62Train = 0.00152264\n",
      "Iter 2820 ---- Process: 5.64Train = 0.00127887\n",
      "Iter 2830 ---- Process: 5.66Train = 0.00101087\n",
      "Iter 2840 ---- Process: 5.68Train = 0.000756078\n",
      "Iter 2850 ---- Process: 5.70Train = 0.00123991\n",
      "Iter 2860 ---- Process: 5.72Train = 0.00156405\n",
      "Iter 2870 ---- Process: 5.74Train = 0.000826288\n",
      "Iter 2880 ---- Process: 5.76Train = 0.000979634\n",
      "Iter 2890 ---- Process: 5.78Train = 0.00144448\n",
      "Iter 2900 ---- Process: 5.80Train = 0.00146521\n",
      "Iter 2910 ---- Process: 5.82Train = 0.00113809\n",
      "Iter 2920 ---- Process: 5.84Train = 0.00107073\n",
      "Iter 2930 ---- Process: 5.86Train = 0.00177712\n",
      "Iter 2940 ---- Process: 5.88Train = 0.00118735\n",
      "Iter 2950 ---- Process: 5.90Train = 0.000851971\n",
      "Iter 2960 ---- Process: 5.92Train = 0.0024385\n",
      "Iter 2970 ---- Process: 5.94Train = 0.00123261\n",
      "Iter 2980 ---- Process: 5.96Train = 0.00138844\n",
      "Iter 2990 ---- Process: 5.98Train = 0.00183867\n",
      "Iter 3000 ---- Process: 6.00Train = 0.00146422\n",
      "Iter 3010 ---- Process: 6.02Train = 0.00125776\n",
      "Iter 3020 ---- Process: 6.04Train = 0.00119326\n",
      "Iter 3030 ---- Process: 6.06Train = 0.000837574\n",
      "Iter 3040 ---- Process: 6.08Train = 0.00151302\n",
      "Iter 3050 ---- Process: 6.10Train = 0.000934187\n",
      "Iter 3060 ---- Process: 6.12Train = 0.000794202\n",
      "Iter 3070 ---- Process: 6.14Train = 0.000725499\n",
      "Iter 3080 ---- Process: 6.16Train = 0.00179536\n",
      "Iter 3090 ---- Process: 6.18Train = 0.000622765\n",
      "Iter 3100 ---- Process: 6.20Train = 0.00113578\n",
      "Iter 3110 ---- Process: 6.22Train = 0.00156229\n",
      "Iter 3120 ---- Process: 6.24Train = 0.00153552\n",
      "Iter 3130 ---- Process: 6.26Train = 0.000558364\n",
      "Iter 3140 ---- Process: 6.28Train = 0.000968067\n",
      "Iter 3150 ---- Process: 6.30Train = 0.00158466\n",
      "Iter 3160 ---- Process: 6.32Train = 0.00100815\n",
      "Iter 3170 ---- Process: 6.34Train = 0.000810029\n",
      "Iter 3180 ---- Process: 6.36Train = 0.00135628\n",
      "Iter 3190 ---- Process: 6.38Train = 0.00101391\n",
      "Iter 3200 ---- Process: 6.40Train = 0.00102113\n",
      "Iter 3210 ---- Process: 6.42Train = 0.00116444\n",
      "Iter 3220 ---- Process: 6.44Train = 0.000903862\n",
      "Iter 3230 ---- Process: 6.46Train = 0.000535511\n",
      "Iter 3240 ---- Process: 6.48Train = 0.000791008\n",
      "Iter 3250 ---- Process: 6.50Train = 0.00133895\n",
      "Iter 3260 ---- Process: 6.52Train = 0.000880128\n",
      "Iter 3270 ---- Process: 6.54Train = 0.0010102\n",
      "Iter 3280 ---- Process: 6.56Train = 0.000975539\n",
      "Iter 3290 ---- Process: 6.58Train = 0.000810152\n",
      "Iter 3300 ---- Process: 6.60Train = 0.0013344\n",
      "Iter 3310 ---- Process: 6.62Train = 0.000707668\n",
      "Iter 3320 ---- Process: 6.64Train = 0.000494675\n",
      "Iter 3330 ---- Process: 6.66Train = 0.000893823\n",
      "Iter 3340 ---- Process: 6.68Train = 0.000455705\n",
      "Iter 3350 ---- Process: 6.70Train = 0.00099528\n",
      "Iter 3360 ---- Process: 6.72Train = 0.00117577\n",
      "Iter 3370 ---- Process: 6.74Train = 0.000810884\n",
      "Iter 3380 ---- Process: 6.76Train = 0.00116237\n",
      "Iter 3390 ---- Process: 6.78Train = 0.00109863\n",
      "Iter 3400 ---- Process: 6.80Train = 0.0010821\n",
      "Iter 3410 ---- Process: 6.82Train = 0.000853296\n",
      "Iter 3420 ---- Process: 6.84Train = 0.00088909\n",
      "Iter 3430 ---- Process: 6.86Train = 0.00213805\n",
      "Iter 3440 ---- Process: 6.88Train = 0.00147198\n",
      "Iter 3450 ---- Process: 6.90Train = 0.001326\n",
      "Iter 3460 ---- Process: 6.92Train = 0.000797502\n",
      "Iter 3470 ---- Process: 6.94Train = 0.000785075\n",
      "Iter 3480 ---- Process: 6.96Train = 0.000978267\n",
      "Iter 3490 ---- Process: 6.98Train = 0.000786585\n",
      "Iter 3500 ---- Process: 7.00Train = 0.00101133\n",
      "Iter 3510 ---- Process: 7.02Train = 0.000783794\n",
      "Iter 3520 ---- Process: 7.04Train = 0.000605528\n",
      "Iter 3530 ---- Process: 7.06Train = 0.000856303\n",
      "Iter 3540 ---- Process: 7.08Train = 0.00109154\n",
      "Iter 3550 ---- Process: 7.10Train = 0.000745065\n",
      "Iter 3560 ---- Process: 7.12Train = 0.0011183\n",
      "Iter 3570 ---- Process: 7.14Train = 0.000731346\n",
      "Iter 3580 ---- Process: 7.16Train = 0.00141512\n",
      "Iter 3590 ---- Process: 7.18Train = 0.00056147\n",
      "Iter 3600 ---- Process: 7.20Train = 0.000851185\n",
      "Iter 3610 ---- Process: 7.22Train = 0.00142711\n",
      "Iter 3620 ---- Process: 7.24Train = 0.00145615\n",
      "Iter 3630 ---- Process: 7.26Train = 0.000658783\n",
      "Iter 3640 ---- Process: 7.28Train = 0.000701135\n",
      "Iter 3650 ---- Process: 7.30Train = 0.000771764\n",
      "Iter 3660 ---- Process: 7.32Train = 0.00116924\n",
      "Iter 3670 ---- Process: 7.34Train = 0.000997068\n",
      "Iter 3680 ---- Process: 7.36Train = 0.0005364\n",
      "Iter 3690 ---- Process: 7.38Train = 0.000901328\n",
      "Iter 3700 ---- Process: 7.40Train = 0.000608843\n",
      "Iter 3710 ---- Process: 7.42Train = 0.000591601\n",
      "Iter 3720 ---- Process: 7.44Train = 0.000529708\n",
      "Iter 3730 ---- Process: 7.46Train = 0.000995893\n",
      "Iter 3740 ---- Process: 7.48Train = 0.000461543\n",
      "Iter 3750 ---- Process: 7.50Train = 0.00134241\n",
      "Iter 3760 ---- Process: 7.52Train = 0.0011232\n",
      "Iter 3770 ---- Process: 7.54Train = 0.00054742\n",
      "Iter 3780 ---- Process: 7.56Train = 0.000929428\n",
      "Iter 3790 ---- Process: 7.58Train = 0.00125135\n",
      "Iter 3800 ---- Process: 7.60Train = 0.00108602\n",
      "Iter 3810 ---- Process: 7.62Train = 0.000865225\n",
      "Iter 3820 ---- Process: 7.64Train = 0.000825128\n",
      "Iter 3830 ---- Process: 7.66Train = 0.00110711\n",
      "Iter 3840 ---- Process: 7.68Train = 0.000597044\n",
      "Iter 3850 ---- Process: 7.70Train = 0.000969458\n",
      "Iter 3860 ---- Process: 7.72Train = 0.000889046\n",
      "Iter 3870 ---- Process: 7.74Train = 0.00162882\n",
      "Iter 3880 ---- Process: 7.76Train = 0.000704593\n",
      "Iter 3890 ---- Process: 7.78Train = 0.000487343\n",
      "Iter 3900 ---- Process: 7.80Train = 0.000925619\n",
      "Iter 3910 ---- Process: 7.82Train = 0.000709798\n",
      "Iter 3920 ---- Process: 7.84Train = 0.00041741\n",
      "Iter 3930 ---- Process: 7.86Train = 0.000876089\n",
      "Iter 3940 ---- Process: 7.88Train = 0.00123105\n",
      "Iter 3950 ---- Process: 7.90Train = 0.000623959\n",
      "Iter 3960 ---- Process: 7.92Train = 0.000659684\n",
      "Iter 3970 ---- Process: 7.94Train = 0.00132244\n",
      "Iter 3980 ---- Process: 7.96Train = 0.00112276\n",
      "Iter 3990 ---- Process: 7.98Train = 0.000888296\n",
      "Iter 4000 ---- Process: 8.00Train = 0.0010695\n",
      "Iter 4010 ---- Process: 8.02Train = 0.000493054\n",
      "Iter 4020 ---- Process: 8.04Train = 0.000771523\n",
      "Iter 4030 ---- Process: 8.06Train = 0.000800844\n",
      "Iter 4040 ---- Process: 8.08Train = 0.000437216\n",
      "Iter 4050 ---- Process: 8.10Train = 0.000436114\n",
      "Iter 4060 ---- Process: 8.12Train = 0.000854338\n",
      "Iter 4070 ---- Process: 8.14Train = 0.000744754\n",
      "Iter 4080 ---- Process: 8.16Train = 0.000928361\n",
      "Iter 4090 ---- Process: 8.18Train = 0.000835956\n",
      "Iter 4100 ---- Process: 8.20Train = 0.000638887\n",
      "Iter 4110 ---- Process: 8.22Train = 0.000550737\n",
      "Iter 4120 ---- Process: 8.24Train = 0.000392615\n",
      "Iter 4130 ---- Process: 8.26Train = 0.000733712\n",
      "Iter 4140 ---- Process: 8.28Train = 0.000867131\n",
      "Iter 4150 ---- Process: 8.30Train = 0.000454347\n",
      "Iter 4160 ---- Process: 8.32Train = 0.000441643\n",
      "Iter 4170 ---- Process: 8.34Train = 0.000660205\n",
      "Iter 4180 ---- Process: 8.36Train = 0.000754742\n",
      "Iter 4190 ---- Process: 8.38Train = 0.00079214\n",
      "Iter 4200 ---- Process: 8.40Train = 0.00129509\n",
      "Iter 4210 ---- Process: 8.42Train = 0.000423068\n",
      "Iter 4220 ---- Process: 8.44Train = 0.000265597\n",
      "Iter 4230 ---- Process: 8.46Train = 0.000720373\n",
      "Iter 4240 ---- Process: 8.48Train = 0.00115747\n",
      "Iter 4250 ---- Process: 8.50Train = 0.000616067\n",
      "Iter 4260 ---- Process: 8.52Train = 0.000637071\n",
      "Iter 4270 ---- Process: 8.54Train = 0.000602205\n",
      "Iter 4280 ---- Process: 8.56Train = 0.000774424\n",
      "Iter 4290 ---- Process: 8.58Train = 0.000836807\n",
      "Iter 4300 ---- Process: 8.60Train = 0.00080294\n",
      "Iter 4310 ---- Process: 8.62Train = 0.000577618\n",
      "Iter 4320 ---- Process: 8.64Train = 0.00105382\n",
      "Iter 4330 ---- Process: 8.66Train = 0.00095001\n",
      "Iter 4340 ---- Process: 8.68Train = 0.000493411\n",
      "Iter 4350 ---- Process: 8.70Train = 0.000430684\n",
      "Iter 4360 ---- Process: 8.72Train = 0.000530337\n",
      "Iter 4370 ---- Process: 8.74Train = 0.000655538\n",
      "Iter 4380 ---- Process: 8.76Train = 0.000649497\n",
      "Iter 4390 ---- Process: 8.78Train = 0.0011088\n",
      "Iter 4400 ---- Process: 8.80Train = 0.0007505\n",
      "Iter 4410 ---- Process: 8.82Train = 0.000591622\n",
      "Iter 4420 ---- Process: 8.84Train = 0.000569783\n",
      "Iter 4430 ---- Process: 8.86Train = 0.000661827\n",
      "Iter 4440 ---- Process: 8.88Train = 0.000641867\n",
      "Iter 4450 ---- Process: 8.90Train = 0.00045088\n",
      "Iter 4460 ---- Process: 8.92Train = 0.00144977\n",
      "Iter 4470 ---- Process: 8.94Train = 0.000666204\n",
      "Iter 4480 ---- Process: 8.96Train = 0.000659403\n",
      "Iter 4490 ---- Process: 8.98Train = 0.000623341\n",
      "Iter 4500 ---- Process: 9.00Train = 0.000490339\n",
      "Iter 4510 ---- Process: 9.02Train = 0.000456216\n",
      "Iter 4520 ---- Process: 9.04Train = 0.00048321\n",
      "Iter 4530 ---- Process: 9.06Train = 0.0013592\n",
      "Iter 4540 ---- Process: 9.08Train = 0.000438886\n",
      "Iter 4550 ---- Process: 9.10Train = 0.000807126\n",
      "Iter 4560 ---- Process: 9.12Train = 0.000531341\n",
      "Iter 4570 ---- Process: 9.14Train = 0.000386675\n",
      "Iter 4580 ---- Process: 9.16Train = 0.00102106\n",
      "Iter 4590 ---- Process: 9.18Train = 0.000382441\n",
      "Iter 4600 ---- Process: 9.20Train = 0.000513781\n",
      "Iter 4610 ---- Process: 9.22Train = 0.00129008\n",
      "Iter 4620 ---- Process: 9.24Train = 0.000947305\n",
      "Iter 4630 ---- Process: 9.26Train = 0.000501545\n",
      "Iter 4640 ---- Process: 9.28Train = 0.000736067\n",
      "Iter 4650 ---- Process: 9.30Train = 0.00139403\n",
      "Iter 4660 ---- Process: 9.32Train = 0.000543081\n",
      "Iter 4670 ---- Process: 9.34Train = 0.000746164\n",
      "Iter 4680 ---- Process: 9.36Train = 0.00051233\n",
      "Iter 4690 ---- Process: 9.38Train = 0.000713851\n",
      "Iter 4700 ---- Process: 9.40Train = 0.000995914\n",
      "Iter 4710 ---- Process: 9.42Train = 0.000691065\n",
      "Iter 4720 ---- Process: 9.44Train = 0.000684882\n",
      "Iter 4730 ---- Process: 9.46Train = 0.000715559\n",
      "Iter 4740 ---- Process: 9.48Train = 0.0012181\n",
      "Iter 4750 ---- Process: 9.50Train = 0.00123074\n",
      "Iter 4760 ---- Process: 9.52Train = 0.000638983\n",
      "Iter 4770 ---- Process: 9.54Train = 0.000735946\n",
      "Iter 4780 ---- Process: 9.56Train = 0.000490382\n",
      "Iter 4790 ---- Process: 9.58Train = 0.000417096\n",
      "Iter 4800 ---- Process: 9.60Train = 0.000568539\n",
      "Iter 4810 ---- Process: 9.62Train = 0.000434768\n",
      "Iter 4820 ---- Process: 9.64Train = 0.000752887\n",
      "Iter 4830 ---- Process: 9.66Train = 0.0005676\n",
      "Iter 4840 ---- Process: 9.68Train = 0.00101204\n",
      "Iter 4850 ---- Process: 9.70Train = 0.000789662\n",
      "Iter 4860 ---- Process: 9.72Train = 0.00054659\n",
      "Iter 4870 ---- Process: 9.74Train = 0.000828609\n",
      "Iter 4880 ---- Process: 9.76Train = 0.00084729\n",
      "Iter 4890 ---- Process: 9.78Train = 0.00062194\n",
      "Iter 4900 ---- Process: 9.80Train = 0.000731492\n",
      "Iter 4910 ---- Process: 9.82Train = 0.000793657\n",
      "Iter 4920 ---- Process: 9.84Train = 0.000567497\n",
      "Iter 4930 ---- Process: 9.86Train = 0.000717195\n",
      "Iter 4940 ---- Process: 9.88Train = 0.000710713\n",
      "Iter 4950 ---- Process: 9.90Train = 0.00101057\n",
      "Iter 4960 ---- Process: 9.92Train = 0.000404407\n",
      "Iter 4970 ---- Process: 9.94Train = 0.000502899\n",
      "Iter 4980 ---- Process: 9.96Train = 0.000712178\n",
      "Iter 4990 ---- Process: 9.98Train = 0.000530107\n",
      "Iter 5000 ---- Process: 10.00Train = 0.000499533\n",
      "Iter 5010 ---- Process: 10.02Train = 0.000532324\n",
      "Iter 5020 ---- Process: 10.04Train = 0.000512056\n",
      "Iter 5030 ---- Process: 10.06Train = 0.000635195\n",
      "Iter 5040 ---- Process: 10.08Train = 0.000347398\n",
      "Iter 5050 ---- Process: 10.10Train = 0.000759008\n",
      "Iter 5060 ---- Process: 10.12Train = 0.00043216\n",
      "Iter 5070 ---- Process: 10.14Train = 0.000475252\n",
      "Iter 5080 ---- Process: 10.16Train = 0.000350614\n",
      "Iter 5090 ---- Process: 10.18Train = 0.000185368\n",
      "Iter 5100 ---- Process: 10.20Train = 0.000752867\n",
      "Iter 5110 ---- Process: 10.22Train = 0.000317372\n",
      "Iter 5120 ---- Process: 10.24Train = 0.000535451\n",
      "Iter 5130 ---- Process: 10.26Train = 0.000741303\n",
      "Iter 5140 ---- Process: 10.28Train = 0.000398456\n",
      "Iter 5150 ---- Process: 10.30Train = 0.000711592\n",
      "Iter 5160 ---- Process: 10.32Train = 0.000518192\n",
      "Iter 5170 ---- Process: 10.34Train = 0.000497458\n",
      "Iter 5180 ---- Process: 10.36Train = 0.000418211\n",
      "Iter 5190 ---- Process: 10.38Train = 0.000967837\n",
      "Iter 5200 ---- Process: 10.40Train = 0.000420838\n",
      "Iter 5210 ---- Process: 10.42Train = 0.00137668\n",
      "Iter 5220 ---- Process: 10.44Train = 0.000568502\n",
      "Iter 5230 ---- Process: 10.46Train = 0.000823106\n",
      "Iter 5240 ---- Process: 10.48Train = 0.000461465\n",
      "Iter 5250 ---- Process: 10.50Train = 0.000570723\n",
      "Iter 5260 ---- Process: 10.52Train = 0.000661477\n",
      "Iter 5270 ---- Process: 10.54Train = 0.000518575\n",
      "Iter 5280 ---- Process: 10.56Train = 0.000564254\n",
      "Iter 5290 ---- Process: 10.58Train = 0.000402754\n",
      "Iter 5300 ---- Process: 10.60Train = 0.000397415\n",
      "Iter 5310 ---- Process: 10.62Train = 0.000551428\n",
      "Iter 5320 ---- Process: 10.64Train = 0.0010515\n",
      "Iter 5330 ---- Process: 10.66Train = 0.000882088\n",
      "Iter 5340 ---- Process: 10.68Train = 0.000312982\n",
      "Iter 5350 ---- Process: 10.70Train = 0.000296553\n",
      "Iter 5360 ---- Process: 10.72Train = 0.000463275\n",
      "Iter 5370 ---- Process: 10.74Train = 0.000533175\n",
      "Iter 5380 ---- Process: 10.76Train = 0.000624581\n",
      "Iter 5390 ---- Process: 10.78Train = 0.000903074\n",
      "Iter 5400 ---- Process: 10.80Train = 0.000348111\n",
      "Iter 5410 ---- Process: 10.82Train = 0.000333269\n",
      "Iter 5420 ---- Process: 10.84Train = 0.000831575\n",
      "Iter 5430 ---- Process: 10.86Train = 0.00031969\n",
      "Iter 5440 ---- Process: 10.88Train = 0.000584801\n",
      "Iter 5450 ---- Process: 10.90Train = 0.000550872\n",
      "Iter 5460 ---- Process: 10.92Train = 0.000393071\n",
      "Iter 5470 ---- Process: 10.94Train = 0.000448902\n",
      "Iter 5480 ---- Process: 10.96Train = 0.000583826\n",
      "Iter 5490 ---- Process: 10.98Train = 0.000449322\n",
      "Iter 5500 ---- Process: 11.00Train = 0.000645549\n",
      "Iter 5510 ---- Process: 11.02Train = 0.00033474\n",
      "Iter 5520 ---- Process: 11.04Train = 0.000442187\n",
      "Iter 5530 ---- Process: 11.06Train = 0.000361942\n",
      "Iter 5540 ---- Process: 11.08Train = 0.000815155\n",
      "Iter 5550 ---- Process: 11.10Train = 0.0004104\n",
      "Iter 5560 ---- Process: 11.12Train = 0.000547814\n",
      "Iter 5570 ---- Process: 11.14Train = 0.000583372\n",
      "Iter 5580 ---- Process: 11.16Train = 0.00121117\n",
      "Iter 5590 ---- Process: 11.18Train = 0.000441213\n",
      "Iter 5600 ---- Process: 11.20Train = 0.000331508\n",
      "Iter 5610 ---- Process: 11.22Train = 0.00108353\n",
      "Iter 5620 ---- Process: 11.24Train = 0.000374557\n",
      "Iter 5630 ---- Process: 11.26Train = 0.000339293\n",
      "Iter 5640 ---- Process: 11.28Train = 0.000447382\n",
      "Iter 5650 ---- Process: 11.30Train = 0.000523133\n",
      "Iter 5660 ---- Process: 11.32Train = 0.000858348\n",
      "Iter 5670 ---- Process: 11.34Train = 0.000295111\n",
      "Iter 5680 ---- Process: 11.36Train = 0.000809743\n",
      "Iter 5690 ---- Process: 11.38Train = 0.000374164\n",
      "Iter 5700 ---- Process: 11.40Train = 0.000383803\n",
      "Iter 5710 ---- Process: 11.42Train = 0.000365656\n",
      "Iter 5720 ---- Process: 11.44Train = 0.000560076\n",
      "Iter 5730 ---- Process: 11.46Train = 0.000469839\n",
      "Iter 5740 ---- Process: 11.48Train = 0.000613455\n",
      "Iter 5750 ---- Process: 11.50Train = 0.000617741\n",
      "Iter 5760 ---- Process: 11.52Train = 0.00036651\n",
      "Iter 5770 ---- Process: 11.54Train = 0.000264881\n",
      "Iter 5780 ---- Process: 11.56Train = 0.000423532\n",
      "Iter 5790 ---- Process: 11.58Train = 0.00107067\n",
      "Iter 5800 ---- Process: 11.60Train = 0.000476889\n",
      "Iter 5810 ---- Process: 11.62Train = 0.000773464\n",
      "Iter 5820 ---- Process: 11.64Train = 0.000906021\n",
      "Iter 5830 ---- Process: 11.66Train = 0.000315626\n",
      "Iter 5840 ---- Process: 11.68Train = 0.000577394\n",
      "Iter 5850 ---- Process: 11.70Train = 0.000429249\n",
      "Iter 5860 ---- Process: 11.72Train = 0.000774891\n",
      "Iter 5870 ---- Process: 11.74Train = 0.000583174\n",
      "Iter 5880 ---- Process: 11.76Train = 0.000393669\n",
      "Iter 5890 ---- Process: 11.78Train = 0.00074025\n",
      "Iter 5900 ---- Process: 11.80Train = 0.000547141\n",
      "Iter 5910 ---- Process: 11.82Train = 0.000213061\n",
      "Iter 5920 ---- Process: 11.84Train = 0.000467439\n",
      "Iter 5930 ---- Process: 11.86Train = 0.000204895\n",
      "Iter 5940 ---- Process: 11.88Train = 0.000259261\n",
      "Iter 5950 ---- Process: 11.90Train = 0.000465617\n",
      "Iter 5960 ---- Process: 11.92Train = 0.000584855\n",
      "Iter 5970 ---- Process: 11.94Train = 0.000433281\n",
      "Iter 5980 ---- Process: 11.96Train = 0.000748991\n",
      "Iter 5990 ---- Process: 11.98Train = 0.0007387\n",
      "Iter 6000 ---- Process: 12.00Train = 0.000383047\n",
      "Iter 6010 ---- Process: 12.02Train = 0.000495968\n",
      "Iter 6020 ---- Process: 12.04Train = 0.000689787\n",
      "Iter 6030 ---- Process: 12.06Train = 0.000529307\n",
      "Iter 6040 ---- Process: 12.08Train = 0.000211865\n",
      "Iter 6050 ---- Process: 12.10Train = 0.00041199\n",
      "Iter 6060 ---- Process: 12.12Train = 0.000450759\n",
      "Iter 6070 ---- Process: 12.14Train = 0.000447915\n",
      "Iter 6080 ---- Process: 12.16Train = 0.0003374\n",
      "Iter 6090 ---- Process: 12.18Train = 0.000940516\n",
      "Iter 6100 ---- Process: 12.20Train = 0.000386884\n",
      "Iter 6110 ---- Process: 12.22Train = 0.000441679\n",
      "Iter 6120 ---- Process: 12.24Train = 0.000421497\n",
      "Iter 6130 ---- Process: 12.26Train = 0.00023821\n",
      "Iter 6140 ---- Process: 12.28Train = 0.00049098\n",
      "Iter 6150 ---- Process: 12.30Train = 0.00072176\n",
      "Iter 6160 ---- Process: 12.32Train = 0.000422451\n",
      "Iter 6170 ---- Process: 12.34Train = 0.000191835\n",
      "Iter 6180 ---- Process: 12.36Train = 0.000430345\n",
      "Iter 6190 ---- Process: 12.38Train = 0.00063241\n",
      "Iter 6200 ---- Process: 12.40Train = 0.00021697\n",
      "Iter 6210 ---- Process: 12.42Train = 0.000322695\n",
      "Iter 6220 ---- Process: 12.44Train = 0.0002823\n",
      "Iter 6230 ---- Process: 12.46Train = 0.000342743\n",
      "Iter 6240 ---- Process: 12.48Train = 0.000612365\n",
      "Iter 6250 ---- Process: 12.50Train = 0.000361919\n",
      "Iter 6260 ---- Process: 12.52Train = 0.000316574\n",
      "Iter 6270 ---- Process: 12.54Train = 0.000379749\n",
      "Iter 6280 ---- Process: 12.56Train = 0.00019853\n",
      "Iter 6290 ---- Process: 12.58Train = 0.00039244\n",
      "Iter 6300 ---- Process: 12.60Train = 0.000231961\n",
      "Iter 6310 ---- Process: 12.62Train = 0.000397468\n",
      "Iter 6320 ---- Process: 12.64Train = 0.000530896\n",
      "Iter 6330 ---- Process: 12.66Train = 0.000980869\n",
      "Iter 6340 ---- Process: 12.68Train = 0.000270734\n",
      "Iter 6350 ---- Process: 12.70Train = 0.000223472\n",
      "Iter 6360 ---- Process: 12.72Train = 0.000517897\n",
      "Iter 6370 ---- Process: 12.74Train = 0.000795822\n",
      "Iter 6380 ---- Process: 12.76Train = 0.000193457\n",
      "Iter 6390 ---- Process: 12.78Train = 0.000324291\n",
      "Iter 6400 ---- Process: 12.80Train = 0.000619008\n",
      "Iter 6410 ---- Process: 12.82Train = 0.00105773\n",
      "Iter 6420 ---- Process: 12.84Train = 0.000243786\n",
      "Iter 6430 ---- Process: 12.86Train = 0.000221844\n",
      "Iter 6440 ---- Process: 12.88Train = 0.00068579\n",
      "Iter 6450 ---- Process: 12.90Train = 0.00046965\n",
      "Iter 6460 ---- Process: 12.92Train = 0.000219935\n",
      "Iter 6470 ---- Process: 12.94Train = 0.000461107\n",
      "Iter 6480 ---- Process: 12.96Train = 0.000285596\n",
      "Iter 6490 ---- Process: 12.98Train = 0.000178222\n",
      "Iter 6500 ---- Process: 13.00Train = 0.000465571\n",
      "Iter 6510 ---- Process: 13.02Train = 0.000407157\n",
      "Iter 6520 ---- Process: 13.04Train = 0.000228059\n",
      "Iter 6530 ---- Process: 13.06Train = 0.00048527\n",
      "Iter 6540 ---- Process: 13.08Train = 0.000441593\n",
      "Iter 6550 ---- Process: 13.10Train = 0.000191832\n",
      "Iter 6560 ---- Process: 13.12Train = 0.000880867\n",
      "Iter 6570 ---- Process: 13.14Train = 0.000249164\n",
      "Iter 6580 ---- Process: 13.16Train = 0.00035282\n",
      "Iter 6590 ---- Process: 13.18Train = 0.000840343\n",
      "Iter 6600 ---- Process: 13.20Train = 0.000315693\n",
      "Iter 6610 ---- Process: 13.22Train = 0.000254454\n",
      "Iter 6620 ---- Process: 13.24Train = 0.000553444\n",
      "Iter 6630 ---- Process: 13.26Train = 0.000494799\n",
      "Iter 6640 ---- Process: 13.28Train = 0.000207466\n",
      "Iter 6650 ---- Process: 13.30Train = 0.000295285\n",
      "Iter 6660 ---- Process: 13.32Train = 0.000470051\n",
      "Iter 6670 ---- Process: 13.34Train = 0.000270497\n",
      "Iter 6680 ---- Process: 13.36Train = 0.000629983\n",
      "Iter 6690 ---- Process: 13.38Train = 0.000971485\n",
      "Iter 6700 ---- Process: 13.40Train = 0.000156261\n",
      "Iter 6710 ---- Process: 13.42Train = 0.000431807\n",
      "Iter 6720 ---- Process: 13.44Train = 0.000305991\n",
      "Iter 6730 ---- Process: 13.46Train = 0.000229117\n",
      "Iter 6740 ---- Process: 13.48Train = 0.000632423\n",
      "Iter 6750 ---- Process: 13.50Train = 0.000320242\n",
      "Iter 6760 ---- Process: 13.52Train = 0.000908349\n",
      "Iter 6770 ---- Process: 13.54Train = 0.000853074\n",
      "Iter 6780 ---- Process: 13.56Train = 0.000502013\n",
      "Iter 6790 ---- Process: 13.58Train = 0.000241735\n",
      "Iter 6800 ---- Process: 13.60Train = 0.000452386\n",
      "Iter 6810 ---- Process: 13.62Train = 0.000956579\n",
      "Iter 6820 ---- Process: 13.64Train = 0.000410307\n",
      "Iter 6830 ---- Process: 13.66Train = 0.000239761\n",
      "Iter 6840 ---- Process: 13.68Train = 0.000218505\n",
      "Iter 6850 ---- Process: 13.70Train = 0.000805561\n",
      "Iter 6860 ---- Process: 13.72Train = 0.00054926\n",
      "Iter 6870 ---- Process: 13.74Train = 0.000259138\n",
      "Iter 6880 ---- Process: 13.76Train = 0.000199179\n",
      "Iter 6890 ---- Process: 13.78Train = 0.000362528\n",
      "Iter 6900 ---- Process: 13.80Train = 0.000220926\n",
      "Iter 6910 ---- Process: 13.82Train = 0.000108923\n",
      "Iter 6920 ---- Process: 13.84Train = 0.000175887\n",
      "Iter 6930 ---- Process: 13.86Train = 0.000343104\n",
      "Iter 6940 ---- Process: 13.88Train = 0.000269716\n",
      "Iter 6950 ---- Process: 13.90Train = 0.000370073\n",
      "Iter 6960 ---- Process: 13.92Train = 0.000216476\n",
      "Iter 6970 ---- Process: 13.94Train = 0.000184578\n",
      "Iter 6980 ---- Process: 13.96Train = 0.000363107\n",
      "Iter 6990 ---- Process: 13.98Train = 0.000217833\n",
      "Iter 7000 ---- Process: 14.00Train = 0.000695549\n",
      "Iter 7010 ---- Process: 14.02Train = 0.00036802\n",
      "Iter 7020 ---- Process: 14.04Train = 0.000524333\n",
      "Iter 7030 ---- Process: 14.06Train = 0.000309474\n",
      "Iter 7040 ---- Process: 14.08Train = 0.000399447\n",
      "Iter 7050 ---- Process: 14.10Train = 0.000359123\n",
      "Iter 7060 ---- Process: 14.12Train = 0.00037042\n",
      "Iter 7070 ---- Process: 14.14Train = 0.000262754\n",
      "Iter 7080 ---- Process: 14.16Train = 0.000375331\n",
      "Iter 7090 ---- Process: 14.18Train = 0.000230458\n",
      "Iter 7100 ---- Process: 14.20Train = 0.000418835\n",
      "Iter 7110 ---- Process: 14.22Train = 0.000385533\n",
      "Iter 7120 ---- Process: 14.24Train = 0.000504737\n",
      "Iter 7130 ---- Process: 14.26Train = 0.000341199\n",
      "Iter 7140 ---- Process: 14.28Train = 0.000397199\n",
      "Iter 7150 ---- Process: 14.30Train = 0.000402834\n",
      "Iter 7160 ---- Process: 14.32Train = 0.000437283\n",
      "Iter 7170 ---- Process: 14.34Train = 0.000394563\n",
      "Iter 7180 ---- Process: 14.36Train = 0.000475538\n",
      "Iter 7190 ---- Process: 14.38Train = 0.000138717\n",
      "Iter 7200 ---- Process: 14.40Train = 0.000301593\n",
      "Iter 7210 ---- Process: 14.42Train = 0.000468835\n",
      "Iter 7220 ---- Process: 14.44Train = 0.000329169\n",
      "Iter 7230 ---- Process: 14.46Train = 0.000330348\n",
      "Iter 7240 ---- Process: 14.48Train = 0.000835446\n",
      "Iter 7250 ---- Process: 14.50Train = 0.000552534\n",
      "Iter 7260 ---- Process: 14.52Train = 0.00025934\n",
      "Iter 7270 ---- Process: 14.54Train = 0.000542661\n",
      "Iter 7280 ---- Process: 14.56Train = 0.000604349\n",
      "Iter 7290 ---- Process: 14.58Train = 0.000353918\n",
      "Iter 7300 ---- Process: 14.60Train = 0.000390626\n",
      "Iter 7310 ---- Process: 14.62Train = 0.000288742\n",
      "Iter 7320 ---- Process: 14.64Train = 0.000508658\n",
      "Iter 7330 ---- Process: 14.66Train = 0.000199245\n",
      "Iter 7340 ---- Process: 14.68Train = 0.000325042\n",
      "Iter 7350 ---- Process: 14.70Train = 0.00070387\n",
      "Iter 7360 ---- Process: 14.72Train = 0.000310947\n",
      "Iter 7370 ---- Process: 14.74Train = 0.000336516\n",
      "Iter 7380 ---- Process: 14.76Train = 0.00045166\n",
      "Iter 7390 ---- Process: 14.78Train = 0.000528529\n",
      "Iter 7400 ---- Process: 14.80Train = 0.000201532\n",
      "Iter 7410 ---- Process: 14.82Train = 0.000269879\n",
      "Iter 7420 ---- Process: 14.84Train = 0.000420557\n",
      "Iter 7430 ---- Process: 14.86Train = 0.000363998\n",
      "Iter 7440 ---- Process: 14.88Train = 0.000291528\n",
      "Iter 7450 ---- Process: 14.90Train = 0.000573575\n",
      "Iter 7460 ---- Process: 14.92Train = 0.000369491\n",
      "Iter 7470 ---- Process: 14.94Train = 0.000173152\n",
      "Iter 7480 ---- Process: 14.96Train = 0.000255964\n",
      "Iter 7490 ---- Process: 14.98Train = 0.000279956\n",
      "Iter 7500 ---- Process: 15.00Train = 0.000130997\n",
      "Iter 7510 ---- Process: 15.02Train = 0.000435084\n",
      "Iter 7520 ---- Process: 15.04Train = 0.00057946\n",
      "Iter 7530 ---- Process: 15.06Train = 0.000148955\n",
      "Iter 7540 ---- Process: 15.08Train = 0.000172942\n",
      "Iter 7550 ---- Process: 15.10Train = 0.000211538\n",
      "Iter 7560 ---- Process: 15.12Train = 0.000301506\n",
      "Iter 7570 ---- Process: 15.14Train = 0.000182408\n",
      "Iter 7580 ---- Process: 15.16Train = 0.000245497\n",
      "Iter 7590 ---- Process: 15.18Train = 0.00058869\n",
      "Iter 7600 ---- Process: 15.20Train = 0.000349288\n",
      "Iter 7610 ---- Process: 15.22Train = 0.000401622\n",
      "Iter 7620 ---- Process: 15.24Train = 0.000233325\n",
      "Iter 7630 ---- Process: 15.26Train = 0.000480412\n",
      "Iter 7640 ---- Process: 15.28Train = 0.000401962\n",
      "Iter 7650 ---- Process: 15.30Train = 0.000219144\n",
      "Iter 7660 ---- Process: 15.32Train = 0.000677596\n",
      "Iter 7670 ---- Process: 15.34Train = 0.000290036\n",
      "Iter 7680 ---- Process: 15.36Train = 0.000312027\n",
      "Iter 7690 ---- Process: 15.38Train = 0.000948587\n",
      "Iter 7700 ---- Process: 15.40Train = 0.000424538\n",
      "Iter 7710 ---- Process: 15.42Train = 0.00026251\n",
      "Iter 7720 ---- Process: 15.44Train = 0.000261767\n",
      "Iter 7730 ---- Process: 15.46Train = 0.000196173\n",
      "Iter 7740 ---- Process: 15.48Train = 0.000359334\n",
      "Iter 7750 ---- Process: 15.50Train = 0.000465165\n",
      "Iter 7760 ---- Process: 15.52Train = 0.00056297\n",
      "Iter 7770 ---- Process: 15.54Train = 0.000293142\n",
      "Iter 7780 ---- Process: 15.56Train = 0.000432089\n",
      "Iter 7790 ---- Process: 15.58Train = 0.000140701\n",
      "Iter 7800 ---- Process: 15.60Train = 0.000351876\n",
      "Iter 7810 ---- Process: 15.62Train = 0.000372586\n",
      "Iter 7820 ---- Process: 15.64Train = 0.00034247\n",
      "Iter 7830 ---- Process: 15.66Train = 0.000246917\n",
      "Iter 7840 ---- Process: 15.68Train = 0.000592005\n",
      "Iter 7850 ---- Process: 15.70Train = 0.000468491\n",
      "Iter 7860 ---- Process: 15.72Train = 0.000167497\n",
      "Iter 7870 ---- Process: 15.74Train = 0.000169461\n",
      "Iter 7880 ---- Process: 15.76Train = 0.000775095\n",
      "Iter 7890 ---- Process: 15.78Train = 0.000335963\n",
      "Iter 7900 ---- Process: 15.80Train = 0.000331642\n",
      "Iter 7910 ---- Process: 15.82Train = 0.000329433\n",
      "Iter 7920 ---- Process: 15.84Train = 0.00029949\n",
      "Iter 7930 ---- Process: 15.86Train = 0.000205855\n",
      "Iter 7940 ---- Process: 15.88Train = 0.000458947\n",
      "Iter 7950 ---- Process: 15.90Train = 0.000247981\n",
      "Iter 7960 ---- Process: 15.92Train = 0.000198807\n",
      "Iter 7970 ---- Process: 15.94Train = 0.000384975\n",
      "Iter 7980 ---- Process: 15.96Train = 0.000182089\n",
      "Iter 7990 ---- Process: 15.98Train = 0.000136736\n",
      "Iter 8000 ---- Process: 16.00Train = 0.00041378\n",
      "Iter 8010 ---- Process: 16.02Train = 0.000372488\n",
      "Iter 8020 ---- Process: 16.04Train = 0.000617639\n",
      "Iter 8030 ---- Process: 16.06Train = 0.000153625\n",
      "Iter 8040 ---- Process: 16.08Train = 0.000312973\n",
      "Iter 8050 ---- Process: 16.10Train = 0.000211535\n",
      "Iter 8060 ---- Process: 16.12Train = 0.000180044\n",
      "Iter 8070 ---- Process: 16.14Train = 0.000370821\n",
      "Iter 8080 ---- Process: 16.16Train = 0.000392402\n",
      "Iter 8090 ---- Process: 16.18Train = 0.000141714\n",
      "Iter 8100 ---- Process: 16.20Train = 0.000334072\n",
      "Iter 8110 ---- Process: 16.22Train = 0.000276416\n",
      "Iter 8120 ---- Process: 16.24Train = 0.000240448\n",
      "Iter 8130 ---- Process: 16.26Train = 0.000202749\n",
      "Iter 8140 ---- Process: 16.28Train = 0.000349903\n",
      "Iter 8150 ---- Process: 16.30Train = 0.000368446\n",
      "Iter 8160 ---- Process: 16.32Train = 0.000575662\n",
      "Iter 8170 ---- Process: 16.34Train = 0.000249994\n",
      "Iter 8180 ---- Process: 16.36Train = 0.000719717\n",
      "Iter 8190 ---- Process: 16.38Train = 0.000365245\n",
      "Iter 8200 ---- Process: 16.40Train = 0.000237905\n",
      "Iter 8210 ---- Process: 16.42Train = 0.000174358\n",
      "Iter 8220 ---- Process: 16.44Train = 0.000197116\n",
      "Iter 8230 ---- Process: 16.46Train = 0.000454786\n",
      "Iter 8240 ---- Process: 16.48Train = 0.000288457\n",
      "Iter 8250 ---- Process: 16.50Train = 0.000131986\n",
      "Iter 8260 ---- Process: 16.52Train = 0.000211702\n",
      "Iter 8270 ---- Process: 16.54Train = 0.000293402\n",
      "Iter 8280 ---- Process: 16.56Train = 0.000588386\n",
      "Iter 8290 ---- Process: 16.58Train = 0.000286445\n",
      "Iter 8300 ---- Process: 16.60Train = 0.000163037\n",
      "Iter 8310 ---- Process: 16.62Train = 0.00025502\n",
      "Iter 8320 ---- Process: 16.64Train = 0.000378705\n",
      "Iter 8330 ---- Process: 16.66Train = 0.000244705\n",
      "Iter 8340 ---- Process: 16.68Train = 0.000280098\n",
      "Iter 8350 ---- Process: 16.70Train = 0.000181368\n",
      "Iter 8360 ---- Process: 16.72Train = 0.00033527\n",
      "Iter 8370 ---- Process: 16.74Train = 0.000203352\n",
      "Iter 8380 ---- Process: 16.76Train = 0.000247386\n",
      "Iter 8390 ---- Process: 16.78Train = 0.00036272\n",
      "Iter 8400 ---- Process: 16.80Train = 0.000184185\n",
      "Iter 8410 ---- Process: 16.82Train = 0.000457844\n",
      "Iter 8420 ---- Process: 16.84Train = 0.000146734\n",
      "Iter 8430 ---- Process: 16.86Train = 0.000221562\n",
      "Iter 8440 ---- Process: 16.88Train = 0.000243021\n",
      "Iter 8450 ---- Process: 16.90Train = 0.000287303\n",
      "Iter 8460 ---- Process: 16.92Train = 0.000429822\n",
      "Iter 8470 ---- Process: 16.94Train = 0.000386191\n",
      "Iter 8480 ---- Process: 16.96Train = 0.000844953\n",
      "Iter 8490 ---- Process: 16.98Train = 0.000185355\n",
      "Iter 8500 ---- Process: 17.00Train = 0.000116222\n",
      "Iter 8510 ---- Process: 17.02Train = 0.000829545\n",
      "Iter 8520 ---- Process: 17.04Train = 0.000170314\n",
      "Iter 8530 ---- Process: 17.06Train = 0.000160395\n",
      "Iter 8540 ---- Process: 17.08Train = 0.000298371\n",
      "Iter 8550 ---- Process: 17.10Train = 0.00019029\n",
      "Iter 8560 ---- Process: 17.12Train = 0.000411097\n",
      "Iter 8570 ---- Process: 17.14Train = 0.000454693\n",
      "Iter 8580 ---- Process: 17.16Train = 0.000278129\n",
      "Iter 8590 ---- Process: 17.18Train = 0.000239539\n",
      "Iter 8600 ---- Process: 17.20Train = 0.000732754\n",
      "Iter 8610 ---- Process: 17.22Train = 0.000151759\n",
      "Iter 8620 ---- Process: 17.24Train = 0.000250999\n",
      "Iter 8630 ---- Process: 17.26Train = 0.000478317\n",
      "Iter 8640 ---- Process: 17.28Train = 0.000197508\n",
      "Iter 8650 ---- Process: 17.30Train = 0.00012436\n",
      "Iter 8660 ---- Process: 17.32Train = 0.000185528\n",
      "Iter 8670 ---- Process: 17.34Train = 0.000441335\n",
      "Iter 8680 ---- Process: 17.36Train = 7.14396e-05\n",
      "Iter 8690 ---- Process: 17.38Train = 0.000330534\n",
      "Iter 8700 ---- Process: 17.40Train = 0.00026958\n",
      "Iter 8710 ---- Process: 17.42Train = 0.000116495\n",
      "Iter 8720 ---- Process: 17.44Train = 0.000182238\n",
      "Iter 8730 ---- Process: 17.46Train = 0.00039713\n",
      "Iter 8740 ---- Process: 17.48Train = 0.000221535\n",
      "Iter 8750 ---- Process: 17.50Train = 0.000156485\n",
      "Iter 8760 ---- Process: 17.52Train = 0.000212989\n",
      "Iter 8770 ---- Process: 17.54Train = 0.00039928\n",
      "Iter 8780 ---- Process: 17.56Train = 0.000230735\n",
      "Iter 8790 ---- Process: 17.58Train = 0.000312327\n",
      "Iter 8800 ---- Process: 17.60Train = 0.000264166\n",
      "Iter 8810 ---- Process: 17.62Train = 0.000385718\n",
      "Iter 8820 ---- Process: 17.64Train = 0.000238203\n",
      "Iter 8830 ---- Process: 17.66Train = 0.000350002\n",
      "Iter 8840 ---- Process: 17.68Train = 0.000266652\n",
      "Iter 8850 ---- Process: 17.70Train = 0.000253278\n",
      "Iter 8860 ---- Process: 17.72Train = 0.000152614\n",
      "Iter 8870 ---- Process: 17.74Train = 0.000234273\n",
      "Iter 8880 ---- Process: 17.76Train = 0.000414647\n",
      "Iter 8890 ---- Process: 17.78Train = 0.000133754\n",
      "Iter 8900 ---- Process: 17.80Train = 0.000104532\n",
      "Iter 8910 ---- Process: 17.82Train = 0.000244342\n",
      "Iter 8920 ---- Process: 17.84Train = 0.000147611\n",
      "Iter 8930 ---- Process: 17.86Train = 0.000487689\n",
      "Iter 8940 ---- Process: 17.88Train = 0.00025712\n",
      "Iter 8950 ---- Process: 17.90Train = 0.000150409\n",
      "Iter 8960 ---- Process: 17.92Train = 0.000273975\n",
      "Iter 8970 ---- Process: 17.94Train = 0.000276965\n",
      "Iter 8980 ---- Process: 17.96Train = 0.000100453\n",
      "Iter 8990 ---- Process: 17.98Train = 0.00022713\n",
      "Iter 9000 ---- Process: 18.00Train = 0.000366134\n",
      "Iter 9010 ---- Process: 18.02Train = 0.000148739\n",
      "Iter 9020 ---- Process: 18.04Train = 0.000259739\n",
      "Iter 9030 ---- Process: 18.06Train = 0.000136025\n",
      "Iter 9040 ---- Process: 18.08Train = 0.000359312\n",
      "Iter 9050 ---- Process: 18.10Train = 0.00024125\n",
      "Iter 9060 ---- Process: 18.12Train = 0.000135358\n",
      "Iter 9070 ---- Process: 18.14Train = 0.000185607\n",
      "Iter 9080 ---- Process: 18.16Train = 0.000241114\n",
      "Iter 9090 ---- Process: 18.18Train = 0.000252833\n",
      "Iter 9100 ---- Process: 18.20Train = 9.01035e-05\n",
      "Iter 9110 ---- Process: 18.22Train = 0.00046459\n",
      "Iter 9120 ---- Process: 18.24Train = 0.000475878\n",
      "Iter 9130 ---- Process: 18.26Train = 0.000281634\n",
      "Iter 9140 ---- Process: 18.28Train = 0.00019949\n",
      "Iter 9150 ---- Process: 18.30Train = 0.000315156\n",
      "Iter 9160 ---- Process: 18.32Train = 0.000229619\n",
      "Iter 9170 ---- Process: 18.34Train = 0.00047178\n",
      "Iter 9180 ---- Process: 18.36Train = 0.000191099\n",
      "Iter 9190 ---- Process: 18.38Train = 0.000161185\n",
      "Iter 9200 ---- Process: 18.40Train = 0.000203636\n",
      "Iter 9210 ---- Process: 18.42Train = 0.000181511\n",
      "Iter 9220 ---- Process: 18.44Train = 0.000211187\n",
      "Iter 9230 ---- Process: 18.46Train = 0.000225397\n",
      "Iter 9240 ---- Process: 18.48Train = 0.000201388\n",
      "Iter 9250 ---- Process: 18.50Train = 0.000210164\n",
      "Iter 9260 ---- Process: 18.52Train = 0.000172616\n",
      "Iter 9270 ---- Process: 18.54Train = 0.000206964\n",
      "Iter 9280 ---- Process: 18.56Train = 0.000233487\n",
      "Iter 9290 ---- Process: 18.58Train = 0.000375531\n",
      "Iter 9300 ---- Process: 18.60Train = 0.000372827\n",
      "Iter 9310 ---- Process: 18.62Train = 0.000113448\n",
      "Iter 9320 ---- Process: 18.64Train = 0.000146451\n",
      "Iter 9330 ---- Process: 18.66Train = 0.000252635\n",
      "Iter 9340 ---- Process: 18.68Train = 0.000237645\n",
      "Iter 9350 ---- Process: 18.70Train = 0.000239109\n",
      "Iter 9360 ---- Process: 18.72Train = 0.000214733\n",
      "Iter 9370 ---- Process: 18.74Train = 0.000161746\n",
      "Iter 9380 ---- Process: 18.76Train = 0.000259371\n",
      "Iter 9390 ---- Process: 18.78Train = 0.000326623\n",
      "Iter 9400 ---- Process: 18.80Train = 0.000212837\n",
      "Iter 9410 ---- Process: 18.82Train = 0.000315706\n",
      "Iter 9420 ---- Process: 18.84Train = 0.00010496\n",
      "Iter 9430 ---- Process: 18.86Train = 0.00013558\n",
      "Iter 9440 ---- Process: 18.88Train = 0.000284224\n",
      "Iter 9450 ---- Process: 18.90Train = 0.000471793\n",
      "Iter 9460 ---- Process: 18.92Train = 0.000204515\n",
      "Iter 9470 ---- Process: 18.94Train = 0.000181056\n",
      "Iter 9480 ---- Process: 18.96Train = 0.000232044\n",
      "Iter 9490 ---- Process: 18.98Train = 0.000128961\n",
      "Iter 9500 ---- Process: 19.00Train = 9.85353e-05\n",
      "Iter 9510 ---- Process: 19.02Train = 0.00016222\n",
      "Iter 9520 ---- Process: 19.04Train = 0.000195609\n",
      "Iter 9530 ---- Process: 19.06Train = 0.00033842\n",
      "Iter 9540 ---- Process: 19.08Train = 0.000337027\n",
      "Iter 9550 ---- Process: 19.10Train = 0.000294565\n",
      "Iter 9560 ---- Process: 19.12Train = 0.000273886\n",
      "Iter 9570 ---- Process: 19.14Train = 0.000217072\n",
      "Iter 9580 ---- Process: 19.16Train = 0.000324616\n",
      "Iter 9590 ---- Process: 19.18Train = 0.000199202\n",
      "Iter 9600 ---- Process: 19.20Train = 0.000155917\n",
      "Iter 9610 ---- Process: 19.22Train = 0.000200159\n",
      "Iter 9620 ---- Process: 19.24Train = 0.000210327\n",
      "Iter 9630 ---- Process: 19.26Train = 0.000148987\n",
      "Iter 9640 ---- Process: 19.28Train = 0.000126321\n",
      "Iter 9650 ---- Process: 19.30Train = 0.000145682\n",
      "Iter 9660 ---- Process: 19.32Train = 0.00046059\n",
      "Iter 9670 ---- Process: 19.34Train = 0.000197972\n",
      "Iter 9680 ---- Process: 19.36Train = 0.000149124\n",
      "Iter 9690 ---- Process: 19.38Train = 0.000148235\n",
      "Iter 9700 ---- Process: 19.40Train = 0.000170802\n",
      "Iter 9710 ---- Process: 19.42Train = 0.000288972\n",
      "Iter 9720 ---- Process: 19.44Train = 0.000294851\n",
      "Iter 9730 ---- Process: 19.46Train = 0.000201739\n",
      "Iter 9740 ---- Process: 19.48Train = 0.000149295\n",
      "Iter 9750 ---- Process: 19.50Train = 0.000504536\n",
      "Iter 9760 ---- Process: 19.52Train = 9.51427e-05\n",
      "Iter 9770 ---- Process: 19.54Train = 0.000198904\n",
      "Iter 9780 ---- Process: 19.56Train = 0.000337104\n",
      "Iter 9790 ---- Process: 19.58Train = 0.000183736\n",
      "Iter 9800 ---- Process: 19.60Train = 0.000449338\n",
      "Iter 9810 ---- Process: 19.62Train = 0.000191287\n",
      "Iter 9820 ---- Process: 19.64Train = 0.000339805\n",
      "Iter 9830 ---- Process: 19.66Train = 0.000177718\n",
      "Iter 9840 ---- Process: 19.68Train = 0.000142445\n",
      "Iter 9850 ---- Process: 19.70Train = 0.000329012\n",
      "Iter 9860 ---- Process: 19.72Train = 0.000159975\n",
      "Iter 9870 ---- Process: 19.74Train = 0.000486011\n",
      "Iter 9880 ---- Process: 19.76Train = 0.000265237\n",
      "Iter 9890 ---- Process: 19.78Train = 0.000174657\n",
      "Iter 9900 ---- Process: 19.80Train = 0.000282695\n",
      "Iter 9910 ---- Process: 19.82Train = 0.000148307\n",
      "Iter 9920 ---- Process: 19.84Train = 0.000192668\n",
      "Iter 9930 ---- Process: 19.86Train = 0.000453474\n",
      "Iter 9940 ---- Process: 19.88Train = 0.000132886\n",
      "Iter 9950 ---- Process: 19.90Train = 0.000149076\n",
      "Iter 9960 ---- Process: 19.92Train = 0.000322033\n",
      "Iter 9970 ---- Process: 19.94Train = 7.71927e-05\n",
      "Iter 9980 ---- Process: 19.96Train = 0.000106249\n",
      "Iter 9990 ---- Process: 19.98Train = 0.00046053\n",
      "Iter 10000 ---- Process: 20.00Train = 0.000378343\n",
      "Iter 10010 ---- Process: 20.02Train = 0.000400555\n",
      "Iter 10020 ---- Process: 20.04Train = 0.000214891\n",
      "Iter 10030 ---- Process: 20.06Train = 0.000221319\n",
      "Iter 10040 ---- Process: 20.08Train = 0.000292185\n",
      "Iter 10050 ---- Process: 20.10Train = 0.000156961\n",
      "Iter 10060 ---- Process: 20.12Train = 0.000188954\n",
      "Iter 10070 ---- Process: 20.14Train = 0.000156234\n",
      "Iter 10080 ---- Process: 20.16Train = 0.000180163\n",
      "Iter 10090 ---- Process: 20.18Train = 0.000170547\n",
      "Iter 10100 ---- Process: 20.20Train = 0.000153525\n",
      "Iter 10110 ---- Process: 20.22Train = 0.000112053\n",
      "Iter 10120 ---- Process: 20.24Train = 0.000301994\n",
      "Iter 10130 ---- Process: 20.26Train = 0.000308359\n",
      "Iter 10140 ---- Process: 20.28Train = 0.000237067\n",
      "Iter 10150 ---- Process: 20.30Train = 0.000482476\n",
      "Iter 10160 ---- Process: 20.32Train = 0.000218894\n",
      "Iter 10170 ---- Process: 20.34Train = 0.000444319\n",
      "Iter 10180 ---- Process: 20.36Train = 0.000252836\n",
      "Iter 10190 ---- Process: 20.38Train = 0.000229001\n",
      "Iter 10200 ---- Process: 20.40Train = 0.000217335\n",
      "Iter 10210 ---- Process: 20.42Train = 0.000174387\n",
      "Iter 10220 ---- Process: 20.44Train = 0.000133893\n",
      "Iter 10230 ---- Process: 20.46Train = 0.000177176\n",
      "Iter 10240 ---- Process: 20.48Train = 0.000199714\n",
      "Iter 10250 ---- Process: 20.50Train = 0.000357118\n",
      "Iter 10260 ---- Process: 20.52Train = 0.000193934\n",
      "Iter 10270 ---- Process: 20.54Train = 0.000256013\n",
      "Iter 10280 ---- Process: 20.56Train = 0.000216008\n",
      "Iter 10290 ---- Process: 20.58Train = 0.000280765\n",
      "Iter 10300 ---- Process: 20.60Train = 9.84197e-05\n",
      "Iter 10310 ---- Process: 20.62Train = 9.0834e-05\n",
      "Iter 10320 ---- Process: 20.64Train = 0.000245145\n",
      "Iter 10330 ---- Process: 20.66Train = 0.000358644\n",
      "Iter 10340 ---- Process: 20.68Train = 0.000145607\n",
      "Iter 10350 ---- Process: 20.70Train = 9.39101e-05\n",
      "Iter 10360 ---- Process: 20.72Train = 0.000144554\n",
      "Iter 10370 ---- Process: 20.74Train = 0.000201817\n",
      "Iter 10380 ---- Process: 20.76Train = 0.00048417\n",
      "Iter 10390 ---- Process: 20.78Train = 0.00035121\n",
      "Iter 10400 ---- Process: 20.80Train = 0.000167784\n",
      "Iter 10410 ---- Process: 20.82Train = 0.000175832\n",
      "Iter 10420 ---- Process: 20.84Train = 0.000150765\n",
      "Iter 10430 ---- Process: 20.86Train = 0.000474962\n",
      "Iter 10440 ---- Process: 20.88Train = 0.000179363\n",
      "Iter 10450 ---- Process: 20.90Train = 0.000110177\n",
      "Iter 10460 ---- Process: 20.92Train = 0.000214327\n",
      "Iter 10470 ---- Process: 20.94Train = 0.000132389\n",
      "Iter 10480 ---- Process: 20.96Train = 0.000136226\n",
      "Iter 10490 ---- Process: 20.98Train = 0.000126311\n",
      "Iter 10500 ---- Process: 21.00Train = 0.000138517\n",
      "Iter 10510 ---- Process: 21.02Train = 0.00015889\n",
      "Iter 10520 ---- Process: 21.04Train = 0.000167932\n",
      "Iter 10530 ---- Process: 21.06Train = 0.000357301\n",
      "Iter 10540 ---- Process: 21.08Train = 0.000328591\n",
      "Iter 10550 ---- Process: 21.10Train = 0.000139872\n",
      "Iter 10560 ---- Process: 21.12Train = 0.000123694\n",
      "Iter 10570 ---- Process: 21.14Train = 0.000398416\n",
      "Iter 10580 ---- Process: 21.16Train = 0.000267793\n",
      "Iter 10590 ---- Process: 21.18Train = 0.000395737\n",
      "Iter 10600 ---- Process: 21.20Train = 0.000182085\n",
      "Iter 10610 ---- Process: 21.22Train = 0.000136467\n",
      "Iter 10620 ---- Process: 21.24Train = 0.000195566\n",
      "Iter 10630 ---- Process: 21.26Train = 0.000459846\n",
      "Iter 10640 ---- Process: 21.28Train = 0.000109561\n",
      "Iter 10650 ---- Process: 21.30Train = 0.000104438\n",
      "Iter 10660 ---- Process: 21.32Train = 0.00047075\n",
      "Iter 10670 ---- Process: 21.34Train = 0.000191291\n",
      "Iter 10680 ---- Process: 21.36Train = 0.000102674\n",
      "Iter 10690 ---- Process: 21.38Train = 0.000189492\n",
      "Iter 10700 ---- Process: 21.40Train = 0.000228035\n",
      "Iter 10710 ---- Process: 21.42Train = 0.000163775\n",
      "Iter 10720 ---- Process: 21.44Train = 0.000435348\n",
      "Iter 10730 ---- Process: 21.46Train = 0.000188333\n",
      "Iter 10740 ---- Process: 21.48Train = 0.000141663\n",
      "Iter 10750 ---- Process: 21.50Train = 0.000137983\n",
      "Iter 10760 ---- Process: 21.52Train = 0.000308768\n",
      "Iter 10770 ---- Process: 21.54Train = 0.000376221\n",
      "Iter 10780 ---- Process: 21.56Train = 0.000160575\n",
      "Iter 10790 ---- Process: 21.58Train = 0.000204378\n",
      "Iter 10800 ---- Process: 21.60Train = 0.00023351\n",
      "Iter 10810 ---- Process: 21.62Train = 6.81779e-05\n",
      "Iter 10820 ---- Process: 21.64Train = 0.000104804\n",
      "Iter 10830 ---- Process: 21.66Train = 0.000659622\n",
      "Iter 10840 ---- Process: 21.68Train = 0.000158924\n",
      "Iter 10850 ---- Process: 21.70Train = 0.000112586\n",
      "Iter 10860 ---- Process: 21.72Train = 0.000250802\n",
      "Iter 10870 ---- Process: 21.74Train = 0.000372735\n",
      "Iter 10880 ---- Process: 21.76Train = 0.000165476\n",
      "Iter 10890 ---- Process: 21.78Train = 0.000141475\n",
      "Iter 10900 ---- Process: 21.80Train = 0.000214999\n",
      "Iter 10910 ---- Process: 21.82Train = 0.00015718\n",
      "Iter 10920 ---- Process: 21.84Train = 0.00011537\n",
      "Iter 10930 ---- Process: 21.86Train = 0.000145341\n",
      "Iter 10940 ---- Process: 21.88Train = 0.000196272\n",
      "Iter 10950 ---- Process: 21.90Train = 0.000108446\n",
      "Iter 10960 ---- Process: 21.92Train = 0.000124116\n",
      "Iter 10970 ---- Process: 21.94Train = 0.000363722\n",
      "Iter 10980 ---- Process: 21.96Train = 0.000133105\n",
      "Iter 10990 ---- Process: 21.98Train = 0.000170171\n",
      "Iter 11000 ---- Process: 22.00Train = 0.000190354\n",
      "Iter 11010 ---- Process: 22.02Train = 0.000135397\n",
      "Iter 11020 ---- Process: 22.04Train = 0.000396933\n",
      "Iter 11030 ---- Process: 22.06Train = 0.000284913\n",
      "Iter 11040 ---- Process: 22.08Train = 0.000238311\n",
      "Iter 11050 ---- Process: 22.10Train = 0.000150512\n",
      "Iter 11060 ---- Process: 22.12Train = 0.000209104\n",
      "Iter 11070 ---- Process: 22.14Train = 0.000119713\n",
      "Iter 11080 ---- Process: 22.16Train = 0.000202219\n",
      "Iter 11090 ---- Process: 22.18Train = 0.000213553\n",
      "Iter 11100 ---- Process: 22.20Train = 8.87505e-05\n",
      "Iter 11110 ---- Process: 22.22Train = 0.00020733\n",
      "Iter 11120 ---- Process: 22.24Train = 0.000240328\n",
      "Iter 11130 ---- Process: 22.26Train = 0.000185549\n",
      "Iter 11140 ---- Process: 22.28Train = 0.000251588\n",
      "Iter 11150 ---- Process: 22.30Train = 0.000263652\n",
      "Iter 11160 ---- Process: 22.32Train = 0.000211058\n",
      "Iter 11170 ---- Process: 22.34Train = 0.000142378\n",
      "Iter 11180 ---- Process: 22.36Train = 0.000208565\n",
      "Iter 11190 ---- Process: 22.38Train = 0.000208344\n",
      "Iter 11200 ---- Process: 22.40Train = 0.000281923\n",
      "Iter 11210 ---- Process: 22.42Train = 9.3522e-05\n",
      "Iter 11220 ---- Process: 22.44Train = 0.000140055\n",
      "Iter 11230 ---- Process: 22.46Train = 0.000287982\n",
      "Iter 11240 ---- Process: 22.48Train = 0.000139877\n",
      "Iter 11250 ---- Process: 22.50Train = 0.000165691\n",
      "Iter 11260 ---- Process: 22.52Train = 8.53127e-05\n",
      "Iter 11270 ---- Process: 22.54Train = 0.000154592\n",
      "Iter 11280 ---- Process: 22.56Train = 0.000241291\n",
      "Iter 11290 ---- Process: 22.58Train = 0.000130533\n",
      "Iter 11300 ---- Process: 22.60Train = 0.000105922\n",
      "Iter 11310 ---- Process: 22.62Train = 0.000109534\n",
      "Iter 11320 ---- Process: 22.64Train = 0.000301983\n",
      "Iter 11330 ---- Process: 22.66Train = 0.000177567\n",
      "Iter 11340 ---- Process: 22.68Train = 0.000153157\n",
      "Iter 11350 ---- Process: 22.70Train = 0.000228542\n",
      "Iter 11360 ---- Process: 22.72Train = 0.000138214\n",
      "Iter 11370 ---- Process: 22.74Train = 0.000157285\n",
      "Iter 11380 ---- Process: 22.76Train = 0.00014908\n",
      "Iter 11390 ---- Process: 22.78Train = 0.000135308\n",
      "Iter 11400 ---- Process: 22.80Train = 0.00026067\n",
      "Iter 11410 ---- Process: 22.82Train = 0.000107575\n",
      "Iter 11420 ---- Process: 22.84Train = 0.000204057\n",
      "Iter 11430 ---- Process: 22.86Train = 0.000196401\n",
      "Iter 11440 ---- Process: 22.88Train = 0.000141137\n",
      "Iter 11450 ---- Process: 22.90Train = 0.000222985\n",
      "Iter 11460 ---- Process: 22.92Train = 0.000288705\n",
      "Iter 11470 ---- Process: 22.94Train = 0.00018416\n",
      "Iter 11480 ---- Process: 22.96Train = 0.000245136\n",
      "Iter 11490 ---- Process: 22.98Train = 0.000174358\n",
      "Iter 11500 ---- Process: 23.00Train = 0.00012152\n",
      "Iter 11510 ---- Process: 23.02Train = 9.55743e-05\n",
      "Iter 11520 ---- Process: 23.04Train = 0.0001963\n",
      "Iter 11530 ---- Process: 23.06Train = 0.000230413\n",
      "Iter 11540 ---- Process: 23.08Train = 0.000154443\n",
      "Iter 11550 ---- Process: 23.10Train = 0.000166754\n",
      "Iter 11560 ---- Process: 23.12Train = 0.000240523\n",
      "Iter 11570 ---- Process: 23.14Train = 0.000224674\n",
      "Iter 11580 ---- Process: 23.16Train = 0.00024479\n",
      "Iter 11590 ---- Process: 23.18Train = 0.000101589\n",
      "Iter 11600 ---- Process: 23.20Train = 0.000202028\n",
      "Iter 11610 ---- Process: 23.22Train = 0.000229807\n",
      "Iter 11620 ---- Process: 23.24Train = 0.000236444\n",
      "Iter 11630 ---- Process: 23.26Train = 0.000131329\n",
      "Iter 11640 ---- Process: 23.28Train = 0.000146361\n",
      "Iter 11650 ---- Process: 23.30Train = 0.000248742\n",
      "Iter 11660 ---- Process: 23.32Train = 0.000117712\n",
      "Iter 11670 ---- Process: 23.34Train = 0.000204267\n",
      "Iter 11680 ---- Process: 23.36Train = 0.000169842\n",
      "Iter 11690 ---- Process: 23.38Train = 0.000142639\n",
      "Iter 11700 ---- Process: 23.40Train = 0.000146842\n",
      "Iter 11710 ---- Process: 23.42Train = 0.000137288\n",
      "Iter 11720 ---- Process: 23.44Train = 0.000232802\n",
      "Iter 11730 ---- Process: 23.46Train = 0.000198219\n",
      "Iter 11740 ---- Process: 23.48Train = 0.000367165\n",
      "Iter 11750 ---- Process: 23.50Train = 0.000205471\n",
      "Iter 11760 ---- Process: 23.52Train = 0.000196051\n",
      "Iter 11770 ---- Process: 23.54Train = 0.000249746\n",
      "Iter 11780 ---- Process: 23.56Train = 0.000176837\n",
      "Iter 11790 ---- Process: 23.58Train = 0.000143181\n",
      "Iter 11800 ---- Process: 23.60Train = 0.000117188\n",
      "Iter 11810 ---- Process: 23.62Train = 0.000114099\n",
      "Iter 11820 ---- Process: 23.64Train = 0.000235182\n",
      "Iter 11830 ---- Process: 23.66Train = 0.000115819\n",
      "Iter 11840 ---- Process: 23.68Train = 0.00016604\n",
      "Iter 11850 ---- Process: 23.70Train = 0.000208864\n",
      "Iter 11860 ---- Process: 23.72Train = 0.000342394\n",
      "Iter 11870 ---- Process: 23.74Train = 7.41096e-05\n",
      "Iter 11880 ---- Process: 23.76Train = 0.000313438\n",
      "Iter 11890 ---- Process: 23.78Train = 0.000253088\n",
      "Iter 11900 ---- Process: 23.80Train = 0.000111124\n",
      "Iter 11910 ---- Process: 23.82Train = 0.000189342\n",
      "Iter 11920 ---- Process: 23.84Train = 6.73713e-05\n",
      "Iter 11930 ---- Process: 23.86Train = 0.000209795\n",
      "Iter 11940 ---- Process: 23.88Train = 0.000114969\n",
      "Iter 11950 ---- Process: 23.90Train = 0.000216186\n",
      "Iter 11960 ---- Process: 23.92Train = 0.000255981\n",
      "Iter 11970 ---- Process: 23.94Train = 0.000164417\n",
      "Iter 11980 ---- Process: 23.96Train = 0.000171524\n",
      "Iter 11990 ---- Process: 23.98Train = 0.000244142\n",
      "Iter 12000 ---- Process: 24.00Train = 0.000101885\n",
      "Iter 12010 ---- Process: 24.02Train = 8.34593e-05\n",
      "Iter 12020 ---- Process: 24.04Train = 0.000243677\n",
      "Iter 12030 ---- Process: 24.06Train = 0.000240347\n",
      "Iter 12040 ---- Process: 24.08Train = 0.000143292\n",
      "Iter 12050 ---- Process: 24.10Train = 0.000210987\n",
      "Iter 12060 ---- Process: 24.12Train = 0.000114838\n",
      "Iter 12070 ---- Process: 24.14Train = 0.000151613\n",
      "Iter 12080 ---- Process: 24.16Train = 8.4281e-05\n",
      "Iter 12090 ---- Process: 24.18Train = 0.000158647\n",
      "Iter 12100 ---- Process: 24.20Train = 0.000165362\n",
      "Iter 12110 ---- Process: 24.22Train = 0.000136074\n",
      "Iter 12120 ---- Process: 24.24Train = 0.000203148\n",
      "Iter 12130 ---- Process: 24.26Train = 0.000218566\n",
      "Iter 12140 ---- Process: 24.28Train = 0.000136144\n",
      "Iter 12150 ---- Process: 24.30Train = 9.25766e-05\n",
      "Iter 12160 ---- Process: 24.32Train = 0.000109191\n",
      "Iter 12170 ---- Process: 24.34Train = 0.000270918\n",
      "Iter 12180 ---- Process: 24.36Train = 0.000184348\n",
      "Iter 12190 ---- Process: 24.38Train = 0.000294773\n",
      "Iter 12200 ---- Process: 24.40Train = 0.000180452\n",
      "Iter 12210 ---- Process: 24.42Train = 0.000183036\n",
      "Iter 12220 ---- Process: 24.44Train = 0.000237499\n",
      "Iter 12230 ---- Process: 24.46Train = 0.000230104\n",
      "Iter 12240 ---- Process: 24.48Train = 0.00010355\n",
      "Iter 12250 ---- Process: 24.50Train = 0.000120893\n",
      "Iter 12260 ---- Process: 24.52Train = 0.000180502\n",
      "Iter 12270 ---- Process: 24.54Train = 0.000184774\n",
      "Iter 12280 ---- Process: 24.56Train = 0.00012865\n",
      "Iter 12290 ---- Process: 24.58Train = 0.000200973\n",
      "Iter 12300 ---- Process: 24.60Train = 0.000206237\n",
      "Iter 12310 ---- Process: 24.62Train = 0.000194555\n",
      "Iter 12320 ---- Process: 24.64Train = 0.000111218\n",
      "Iter 12330 ---- Process: 24.66Train = 0.000166848\n",
      "Iter 12340 ---- Process: 24.68Train = 0.000119915\n",
      "Iter 12350 ---- Process: 24.70Train = 0.000228334\n",
      "Iter 12360 ---- Process: 24.72Train = 0.000201689\n",
      "Iter 12370 ---- Process: 24.74Train = 0.000216467\n",
      "Iter 12380 ---- Process: 24.76Train = 0.000101497\n",
      "Iter 12390 ---- Process: 24.78Train = 0.000158336\n",
      "Iter 12400 ---- Process: 24.80Train = 0.000127415\n",
      "Iter 12410 ---- Process: 24.82Train = 0.000170701\n",
      "Iter 12420 ---- Process: 24.84Train = 0.000105623\n",
      "Iter 12430 ---- Process: 24.86Train = 9.97802e-05\n",
      "Iter 12440 ---- Process: 24.88Train = 0.000292825\n",
      "Iter 12450 ---- Process: 24.90Train = 0.000206862\n",
      "Iter 12460 ---- Process: 24.92Train = 8.8666e-05\n",
      "Iter 12470 ---- Process: 24.94Train = 0.000118806\n",
      "Iter 12480 ---- Process: 24.96Train = 0.00018134\n",
      "Iter 12490 ---- Process: 24.98Train = 0.000273425\n",
      "Iter 12500 ---- Process: 25.00Train = 0.000237354\n",
      "Iter 12510 ---- Process: 25.02Train = 0.000131775\n",
      "Iter 12520 ---- Process: 25.04Train = 0.000293734\n",
      "Iter 12530 ---- Process: 25.06Train = 0.000105265\n",
      "Iter 12540 ---- Process: 25.08Train = 0.000113273\n",
      "Iter 12550 ---- Process: 25.10Train = 0.000215579\n",
      "Iter 12560 ---- Process: 25.12Train = 0.000154511\n",
      "Iter 12570 ---- Process: 25.14Train = 0.000185714\n",
      "Iter 12580 ---- Process: 25.16Train = 0.000289778\n",
      "Iter 12590 ---- Process: 25.18Train = 0.000186174\n",
      "Iter 12600 ---- Process: 25.20Train = 0.000111835\n",
      "Iter 12610 ---- Process: 25.22Train = 0.000132365\n",
      "Iter 12620 ---- Process: 25.24Train = 0.000171247\n",
      "Iter 12630 ---- Process: 25.26Train = 0.000145465\n",
      "Iter 12640 ---- Process: 25.28Train = 0.00013005\n",
      "Iter 12650 ---- Process: 25.30Train = 8.45083e-05\n",
      "Iter 12660 ---- Process: 25.32Train = 0.000247869\n",
      "Iter 12670 ---- Process: 25.34Train = 0.000147487\n",
      "Iter 12680 ---- Process: 25.36Train = 8.33811e-05\n",
      "Iter 12690 ---- Process: 25.38Train = 0.000100908\n",
      "Iter 12700 ---- Process: 25.40Train = 0.000161678\n",
      "Iter 12710 ---- Process: 25.42Train = 0.000120354\n",
      "Iter 12720 ---- Process: 25.44Train = 9.81655e-05\n",
      "Iter 12730 ---- Process: 25.46Train = 0.000198922\n",
      "Iter 12740 ---- Process: 25.48Train = 0.000112346\n",
      "Iter 12750 ---- Process: 25.50Train = 0.000247762\n",
      "Iter 12760 ---- Process: 25.52Train = 9.19567e-05\n",
      "Iter 12770 ---- Process: 25.54Train = 8.61016e-05\n",
      "Iter 12780 ---- Process: 25.56Train = 0.000113961\n",
      "Iter 12790 ---- Process: 25.58Train = 0.000146258\n",
      "Iter 12800 ---- Process: 25.60Train = 0.000175512\n",
      "Iter 12810 ---- Process: 25.62Train = 0.000173581\n",
      "Iter 12820 ---- Process: 25.64Train = 0.000180917\n",
      "Iter 12830 ---- Process: 25.66Train = 0.000127646\n",
      "Iter 12840 ---- Process: 25.68Train = 0.000134746\n",
      "Iter 12850 ---- Process: 25.70Train = 0.000315942\n",
      "Iter 12860 ---- Process: 25.72Train = 0.000192072\n",
      "Iter 12870 ---- Process: 25.74Train = 0.000305187\n",
      "Iter 12880 ---- Process: 25.76Train = 0.000295997\n",
      "Iter 12890 ---- Process: 25.78Train = 0.000103751\n",
      "Iter 12900 ---- Process: 25.80Train = 0.000115058\n",
      "Iter 12910 ---- Process: 25.82Train = 8.23967e-05\n",
      "Iter 12920 ---- Process: 25.84Train = 0.000287355\n",
      "Iter 12930 ---- Process: 25.86Train = 0.000114695\n",
      "Iter 12940 ---- Process: 25.88Train = 0.000101927\n",
      "Iter 12950 ---- Process: 25.90Train = 0.00032103\n",
      "Iter 12960 ---- Process: 25.92Train = 9.78439e-05\n",
      "Iter 12970 ---- Process: 25.94Train = 0.000105555\n",
      "Iter 12980 ---- Process: 25.96Train = 0.00026117\n",
      "Iter 12990 ---- Process: 25.98Train = 0.000228583\n",
      "Iter 13000 ---- Process: 26.00Train = 0.000196018\n",
      "Iter 13010 ---- Process: 26.02Train = 9.22001e-05\n",
      "Iter 13020 ---- Process: 26.04Train = 0.000134765\n",
      "Iter 13030 ---- Process: 26.06Train = 0.000300883\n",
      "Iter 13040 ---- Process: 26.08Train = 0.000108207\n",
      "Iter 13050 ---- Process: 26.10Train = 0.000101095\n",
      "Iter 13060 ---- Process: 26.12Train = 0.000189216\n",
      "Iter 13070 ---- Process: 26.14Train = 0.00018958\n",
      "Iter 13080 ---- Process: 26.16Train = 7.856e-05\n",
      "Iter 13090 ---- Process: 26.18Train = 0.00010029\n",
      "Iter 13100 ---- Process: 26.20Train = 0.000120443\n",
      "Iter 13110 ---- Process: 26.22Train = 0.000203813\n",
      "Iter 13120 ---- Process: 26.24Train = 0.000164113\n",
      "Iter 13130 ---- Process: 26.26Train = 0.000162188\n",
      "Iter 13140 ---- Process: 26.28Train = 0.000117279\n",
      "Iter 13150 ---- Process: 26.30Train = 0.000164508\n",
      "Iter 13160 ---- Process: 26.32Train = 7.48446e-05\n",
      "Iter 13170 ---- Process: 26.34Train = 0.000124842\n",
      "Iter 13180 ---- Process: 26.36Train = 0.000186911\n",
      "Iter 13190 ---- Process: 26.38Train = 0.000120749\n",
      "Iter 13200 ---- Process: 26.40Train = 0.000162256\n",
      "Iter 13210 ---- Process: 26.42Train = 0.000205334\n",
      "Iter 13220 ---- Process: 26.44Train = 0.000206212\n",
      "Iter 13230 ---- Process: 26.46Train = 0.000184624\n",
      "Iter 13240 ---- Process: 26.48Train = 0.000149953\n",
      "Iter 13250 ---- Process: 26.50Train = 0.000137555\n",
      "Iter 13260 ---- Process: 26.52Train = 0.000195295\n",
      "Iter 13270 ---- Process: 26.54Train = 0.000200447\n",
      "Iter 13280 ---- Process: 26.56Train = 0.000111024\n",
      "Iter 13290 ---- Process: 26.58Train = 0.000146685\n",
      "Iter 13300 ---- Process: 26.60Train = 0.000246989\n",
      "Iter 13310 ---- Process: 26.62Train = 0.000263507\n",
      "Iter 13320 ---- Process: 26.64Train = 0.00010463\n",
      "Iter 13330 ---- Process: 26.66Train = 9.51423e-05\n",
      "Iter 13340 ---- Process: 26.68Train = 0.000244029\n",
      "Iter 13350 ---- Process: 26.70Train = 0.000187366\n",
      "Iter 13360 ---- Process: 26.72Train = 0.000248724\n",
      "Iter 13370 ---- Process: 26.74Train = 0.000132916\n",
      "Iter 13380 ---- Process: 26.76Train = 0.000162187\n",
      "Iter 13390 ---- Process: 26.78Train = 0.000142204\n",
      "Iter 13400 ---- Process: 26.80Train = 9.93746e-05\n",
      "Iter 13410 ---- Process: 26.82Train = 0.000105064\n",
      "Iter 13420 ---- Process: 26.84Train = 0.000201963\n",
      "Iter 13430 ---- Process: 26.86Train = 0.000144922\n",
      "Iter 13440 ---- Process: 26.88Train = 0.000113979\n",
      "Iter 13450 ---- Process: 26.90Train = 7.74052e-05\n",
      "Iter 13460 ---- Process: 26.92Train = 0.000427511\n",
      "Iter 13470 ---- Process: 26.94Train = 0.000141501\n",
      "Iter 13480 ---- Process: 26.96Train = 0.000118911\n",
      "Iter 13490 ---- Process: 26.98Train = 0.000160562\n",
      "Iter 13500 ---- Process: 27.00Train = 0.000113864\n",
      "Iter 13510 ---- Process: 27.02Train = 0.000137818\n",
      "Iter 13520 ---- Process: 27.04Train = 0.000352217\n",
      "Iter 13530 ---- Process: 27.06Train = 0.00011917\n",
      "Iter 13540 ---- Process: 27.08Train = 0.000221314\n",
      "Iter 13550 ---- Process: 27.10Train = 0.00012017\n",
      "Iter 13560 ---- Process: 27.12Train = 0.000249793\n",
      "Iter 13570 ---- Process: 27.14Train = 0.000272194\n",
      "Iter 13580 ---- Process: 27.16Train = 0.000130405\n",
      "Iter 13590 ---- Process: 27.18Train = 0.000138757\n",
      "Iter 13600 ---- Process: 27.20Train = 0.000266803\n",
      "Iter 13610 ---- Process: 27.22Train = 0.000144424\n",
      "Iter 13620 ---- Process: 27.24Train = 0.000109894\n",
      "Iter 13630 ---- Process: 27.26Train = 0.000119972\n",
      "Iter 13640 ---- Process: 27.28Train = 0.000245722\n",
      "Iter 13650 ---- Process: 27.30Train = 0.000135247\n",
      "Iter 13660 ---- Process: 27.32Train = 0.000104162\n",
      "Iter 13670 ---- Process: 27.34Train = 0.000297944\n",
      "Iter 13680 ---- Process: 27.36Train = 0.000135587\n",
      "Iter 13690 ---- Process: 27.38Train = 0.000136569\n",
      "Iter 13700 ---- Process: 27.40Train = 8.37769e-05\n",
      "Iter 13710 ---- Process: 27.42Train = 0.0001395\n",
      "Iter 13720 ---- Process: 27.44Train = 0.000195993\n",
      "Iter 13730 ---- Process: 27.46Train = 0.000127064\n",
      "Iter 13740 ---- Process: 27.48Train = 0.000279728\n",
      "Iter 13750 ---- Process: 27.50Train = 0.000224189\n",
      "Iter 13760 ---- Process: 27.52Train = 0.000183179\n",
      "Iter 13770 ---- Process: 27.54Train = 0.000165961\n",
      "Iter 13780 ---- Process: 27.56Train = 0.000110247\n",
      "Iter 13790 ---- Process: 27.58Train = 0.000128677\n",
      "Iter 13800 ---- Process: 27.60Train = 0.000430339\n",
      "Iter 13810 ---- Process: 27.62Train = 7.03303e-05\n",
      "Iter 13820 ---- Process: 27.64Train = 7.77733e-05\n",
      "Iter 13830 ---- Process: 27.66Train = 0.000263364\n",
      "Iter 13840 ---- Process: 27.68Train = 6.54199e-05\n",
      "Iter 13850 ---- Process: 27.70Train = 0.000160432\n",
      "Iter 13860 ---- Process: 27.72Train = 0.0001175\n",
      "Iter 13870 ---- Process: 27.74Train = 0.000142825\n",
      "Iter 13880 ---- Process: 27.76Train = 0.000115625\n",
      "Iter 13890 ---- Process: 27.78Train = 9.49566e-05\n",
      "Iter 13900 ---- Process: 27.80Train = 0.000108133\n",
      "Iter 13910 ---- Process: 27.82Train = 9.09712e-05\n",
      "Iter 13920 ---- Process: 27.84Train = 9.19697e-05\n",
      "Iter 13930 ---- Process: 27.86Train = 0.000242461\n",
      "Iter 13940 ---- Process: 27.88Train = 0.00011161\n",
      "Iter 13950 ---- Process: 27.90Train = 8.2803e-05\n",
      "Iter 13960 ---- Process: 27.92Train = 0.000229197\n",
      "Iter 13970 ---- Process: 27.94Train = 0.000147491\n",
      "Iter 13980 ---- Process: 27.96Train = 0.000137217\n",
      "Iter 13990 ---- Process: 27.98Train = 0.000279356\n",
      "Iter 14000 ---- Process: 28.00Train = 0.000231748\n",
      "Iter 14010 ---- Process: 28.02Train = 0.000145707\n",
      "Iter 14020 ---- Process: 28.04Train = 0.000345239\n",
      "Iter 14030 ---- Process: 28.06Train = 0.000237534\n",
      "Iter 14040 ---- Process: 28.08Train = 7.26979e-05\n",
      "Iter 14050 ---- Process: 28.10Train = 7.49101e-05\n",
      "Iter 14060 ---- Process: 28.12Train = 0.000335871\n",
      "Iter 14070 ---- Process: 28.14Train = 0.000111547\n",
      "Iter 14080 ---- Process: 28.16Train = 0.000220513\n",
      "Iter 14090 ---- Process: 28.18Train = 7.95901e-05\n",
      "Iter 14100 ---- Process: 28.20Train = 0.000135799\n",
      "Iter 14110 ---- Process: 28.22Train = 0.000123976\n",
      "Iter 14120 ---- Process: 28.24Train = 0.000153367\n",
      "Iter 14130 ---- Process: 28.26Train = 9.30373e-05\n",
      "Iter 14140 ---- Process: 28.28Train = 0.000132738\n",
      "Iter 14150 ---- Process: 28.30Train = 0.000154822\n",
      "Iter 14160 ---- Process: 28.32Train = 9.32742e-05\n",
      "Iter 14170 ---- Process: 28.34Train = 0.000124457\n",
      "Iter 14180 ---- Process: 28.36Train = 0.000165249\n",
      "Iter 14190 ---- Process: 28.38Train = 0.000136181\n",
      "Iter 14200 ---- Process: 28.40Train = 0.000166613\n",
      "Iter 14210 ---- Process: 28.42Train = 0.000225667\n",
      "Iter 14220 ---- Process: 28.44Train = 0.000121634\n",
      "Iter 14230 ---- Process: 28.46Train = 0.000112028\n",
      "Iter 14240 ---- Process: 28.48Train = 0.00031593\n",
      "Iter 14250 ---- Process: 28.50Train = 0.000189315\n",
      "Iter 14260 ---- Process: 28.52Train = 0.000160785\n",
      "Iter 14270 ---- Process: 28.54Train = 0.000177163\n",
      "Iter 14280 ---- Process: 28.56Train = 0.000330091\n",
      "Iter 14290 ---- Process: 28.58Train = 6.30265e-05\n",
      "Iter 14300 ---- Process: 28.60Train = 0.000150686\n",
      "Iter 14310 ---- Process: 28.62Train = 0.000126313\n",
      "Iter 14320 ---- Process: 28.64Train = 0.000192868\n",
      "Iter 14330 ---- Process: 28.66Train = 0.000167931\n",
      "Iter 14340 ---- Process: 28.68Train = 0.000156968\n",
      "Iter 14350 ---- Process: 28.70Train = 0.000142496\n",
      "Iter 14360 ---- Process: 28.72Train = 0.000349485\n",
      "Iter 14370 ---- Process: 28.74Train = 0.000157968\n",
      "Iter 14380 ---- Process: 28.76Train = 0.000123149\n",
      "Iter 14390 ---- Process: 28.78Train = 0.000111926\n",
      "Iter 14400 ---- Process: 28.80Train = 0.000175733\n",
      "Iter 14410 ---- Process: 28.82Train = 0.000125373\n",
      "Iter 14420 ---- Process: 28.84Train = 0.000143181\n",
      "Iter 14430 ---- Process: 28.86Train = 9.0147e-05\n",
      "Iter 14440 ---- Process: 28.88Train = 0.000135043\n",
      "Iter 14450 ---- Process: 28.90Train = 0.000206005\n",
      "Iter 14460 ---- Process: 28.92Train = 7.58149e-05\n",
      "Iter 14470 ---- Process: 28.94Train = 7.32338e-05\n",
      "Iter 14480 ---- Process: 28.96Train = 9.54082e-05\n",
      "Iter 14490 ---- Process: 28.98Train = 0.000356624\n",
      "Iter 14500 ---- Process: 29.00Train = 0.000116686\n",
      "Iter 14510 ---- Process: 29.02Train = 0.00015689\n",
      "Iter 14520 ---- Process: 29.04Train = 0.000192802\n",
      "Iter 14530 ---- Process: 29.06Train = 9.39855e-05\n",
      "Iter 14540 ---- Process: 29.08Train = 6.3989e-05\n",
      "Iter 14550 ---- Process: 29.10Train = 0.000142378\n",
      "Iter 14560 ---- Process: 29.12Train = 0.000146255\n",
      "Iter 14570 ---- Process: 29.14Train = 0.000307577\n",
      "Iter 14580 ---- Process: 29.16Train = 0.00010557\n",
      "Iter 14590 ---- Process: 29.18Train = 0.000107887\n",
      "Iter 14600 ---- Process: 29.20Train = 0.000139255\n",
      "Iter 14610 ---- Process: 29.22Train = 0.000248564\n",
      "Iter 14620 ---- Process: 29.24Train = 0.000122629\n",
      "Iter 14630 ---- Process: 29.26Train = 0.000104402\n",
      "Iter 14640 ---- Process: 29.28Train = 0.000207803\n",
      "Iter 14650 ---- Process: 29.30Train = 0.00012221\n",
      "Iter 14660 ---- Process: 29.32Train = 0.000152146\n",
      "Iter 14670 ---- Process: 29.34Train = 0.00022714\n",
      "Iter 14680 ---- Process: 29.36Train = 0.000102753\n",
      "Iter 14690 ---- Process: 29.38Train = 0.000135696\n",
      "Iter 14700 ---- Process: 29.40Train = 0.000224577\n",
      "Iter 14710 ---- Process: 29.42Train = 8.45047e-05\n",
      "Iter 14720 ---- Process: 29.44Train = 0.000130006\n",
      "Iter 14730 ---- Process: 29.46Train = 0.000106433\n",
      "Iter 14740 ---- Process: 29.48Train = 9.23991e-05\n",
      "Iter 14750 ---- Process: 29.50Train = 0.00022985\n",
      "Iter 14760 ---- Process: 29.52Train = 0.000187645\n",
      "Iter 14770 ---- Process: 29.54Train = 0.000143754\n",
      "Iter 14780 ---- Process: 29.56Train = 7.65494e-05\n",
      "Iter 14790 ---- Process: 29.58Train = 0.000207523\n",
      "Iter 14800 ---- Process: 29.60Train = 0.000156556\n",
      "Iter 14810 ---- Process: 29.62Train = 0.00023801\n",
      "Iter 14820 ---- Process: 29.64Train = 0.000228723\n",
      "Iter 14830 ---- Process: 29.66Train = 0.000106036\n",
      "Iter 14840 ---- Process: 29.68Train = 9.73058e-05\n",
      "Iter 14850 ---- Process: 29.70Train = 0.000151012\n",
      "Iter 14860 ---- Process: 29.72Train = 0.000176517\n",
      "Iter 14870 ---- Process: 29.74Train = 0.000105823\n",
      "Iter 14880 ---- Process: 29.76Train = 7.63507e-05\n",
      "Iter 14890 ---- Process: 29.78Train = 0.000113244\n",
      "Iter 14900 ---- Process: 29.80Train = 0.000285403\n",
      "Iter 14910 ---- Process: 29.82Train = 5.03987e-05\n",
      "Iter 14920 ---- Process: 29.84Train = 0.000100609\n",
      "Iter 14930 ---- Process: 29.86Train = 0.000166149\n",
      "Iter 14940 ---- Process: 29.88Train = 8.40195e-05\n",
      "Iter 14950 ---- Process: 29.90Train = 6.75535e-05\n",
      "Iter 14960 ---- Process: 29.92Train = 0.000118882\n",
      "Iter 14970 ---- Process: 29.94Train = 0.000226851\n",
      "Iter 14980 ---- Process: 29.96Train = 7.78e-05\n",
      "Iter 14990 ---- Process: 29.98Train = 0.000102023\n",
      "Iter 15000 ---- Process: 30.00Train = 0.000152808\n",
      "Iter 15010 ---- Process: 30.02Train = 0.000130335\n",
      "Iter 15020 ---- Process: 30.04Train = 0.000142334\n",
      "Iter 15030 ---- Process: 30.06Train = 0.000132529\n",
      "Iter 15040 ---- Process: 30.08Train = 8.3662e-05\n",
      "Iter 15050 ---- Process: 30.10Train = 0.000174724\n",
      "Iter 15060 ---- Process: 30.12Train = 0.000112687\n",
      "Iter 15070 ---- Process: 30.14Train = 8.95039e-05\n",
      "Iter 15080 ---- Process: 30.16Train = 0.000139049\n",
      "Iter 15090 ---- Process: 30.18Train = 0.000220847\n",
      "Iter 15100 ---- Process: 30.20Train = 0.000159312\n",
      "Iter 15110 ---- Process: 30.22Train = 0.000121364\n",
      "Iter 15120 ---- Process: 30.24Train = 0.000107672\n",
      "Iter 15130 ---- Process: 30.26Train = 0.000118502\n",
      "Iter 15140 ---- Process: 30.28Train = 0.000117564\n",
      "Iter 15150 ---- Process: 30.30Train = 0.000249604\n",
      "Iter 15160 ---- Process: 30.32Train = 0.000107554\n",
      "Iter 15170 ---- Process: 30.34Train = 0.000103531\n",
      "Iter 15180 ---- Process: 30.36Train = 9.94552e-05\n",
      "Iter 15190 ---- Process: 30.38Train = 0.000140286\n",
      "Iter 15200 ---- Process: 30.40Train = 0.000244852\n",
      "Iter 15210 ---- Process: 30.42Train = 0.000122746\n",
      "Iter 15220 ---- Process: 30.44Train = 0.000188792\n",
      "Iter 15230 ---- Process: 30.46Train = 5.7691e-05\n",
      "Iter 15240 ---- Process: 30.48Train = 9.26806e-05\n",
      "Iter 15250 ---- Process: 30.50Train = 0.000205078\n",
      "Iter 15260 ---- Process: 30.52Train = 0.000119253\n",
      "Iter 15270 ---- Process: 30.54Train = 9.9385e-05\n",
      "Iter 15280 ---- Process: 30.56Train = 0.000216313\n",
      "Iter 15290 ---- Process: 30.58Train = 9.70507e-05\n",
      "Iter 15300 ---- Process: 30.60Train = 0.000122972\n",
      "Iter 15310 ---- Process: 30.62Train = 0.000108899\n",
      "Iter 15320 ---- Process: 30.64Train = 7.39641e-05\n",
      "Iter 15330 ---- Process: 30.66Train = 0.000151527\n",
      "Iter 15340 ---- Process: 30.68Train = 0.000160672\n",
      "Iter 15350 ---- Process: 30.70Train = 0.000119664\n",
      "Iter 15360 ---- Process: 30.72Train = 0.000113811\n",
      "Iter 15370 ---- Process: 30.74Train = 0.000116623\n",
      "Iter 15380 ---- Process: 30.76Train = 0.000182396\n",
      "Iter 15390 ---- Process: 30.78Train = 0.000269667\n",
      "Iter 15400 ---- Process: 30.80Train = 9.67955e-05\n",
      "Iter 15410 ---- Process: 30.82Train = 0.000156747\n",
      "Iter 15420 ---- Process: 30.84Train = 0.000211208\n",
      "Iter 15430 ---- Process: 30.86Train = 5.39445e-05\n",
      "Iter 15440 ---- Process: 30.88Train = 0.000114163\n",
      "Iter 15450 ---- Process: 30.90Train = 0.000182373\n",
      "Iter 15460 ---- Process: 30.92Train = 0.000106942\n",
      "Iter 15470 ---- Process: 30.94Train = 6.67875e-05\n",
      "Iter 15480 ---- Process: 30.96Train = 0.000141629\n",
      "Iter 15490 ---- Process: 30.98Train = 0.000148919\n",
      "Iter 15500 ---- Process: 31.00Train = 0.000106899\n",
      "Iter 15510 ---- Process: 31.02Train = 0.000183256\n",
      "Iter 15520 ---- Process: 31.04Train = 4.90588e-05\n",
      "Iter 15530 ---- Process: 31.06Train = 0.00011779\n",
      "Iter 15540 ---- Process: 31.08Train = 0.000173799\n",
      "Iter 15550 ---- Process: 31.10Train = 8.24807e-05\n",
      "Iter 15560 ---- Process: 31.12Train = 0.000156473\n",
      "Iter 15570 ---- Process: 31.14Train = 9.50799e-05\n",
      "Iter 15580 ---- Process: 31.16Train = 8.08216e-05\n",
      "Iter 15590 ---- Process: 31.18Train = 0.000188149\n",
      "Iter 15600 ---- Process: 31.20Train = 0.000145625\n",
      "Iter 15610 ---- Process: 31.22Train = 0.000212911\n",
      "Iter 15620 ---- Process: 31.24Train = 0.000101716\n",
      "Iter 15630 ---- Process: 31.26Train = 0.000104789\n",
      "Iter 15640 ---- Process: 31.28Train = 9.78597e-05\n",
      "Iter 15650 ---- Process: 31.30Train = 6.36623e-05\n",
      "Iter 15660 ---- Process: 31.32Train = 0.000144771\n",
      "Iter 15670 ---- Process: 31.34Train = 0.000156858\n",
      "Iter 15680 ---- Process: 31.36Train = 0.000132052\n",
      "Iter 15690 ---- Process: 31.38Train = 6.19016e-05\n",
      "Iter 15700 ---- Process: 31.40Train = 0.000144129\n",
      "Iter 15710 ---- Process: 31.42Train = 0.000128881\n",
      "Iter 15720 ---- Process: 31.44Train = 0.000129306\n",
      "Iter 15730 ---- Process: 31.46Train = 0.000113055\n",
      "Iter 15740 ---- Process: 31.48Train = 0.000102442\n",
      "Iter 15750 ---- Process: 31.50Train = 0.000232728\n",
      "Iter 15760 ---- Process: 31.52Train = 7.84469e-05\n",
      "Iter 15770 ---- Process: 31.54Train = 0.000154195\n",
      "Iter 15780 ---- Process: 31.56Train = 0.000103673\n",
      "Iter 15790 ---- Process: 31.58Train = 0.000104176\n",
      "Iter 15800 ---- Process: 31.60Train = 6.05685e-05\n",
      "Iter 15810 ---- Process: 31.62Train = 0.000116618\n",
      "Iter 15820 ---- Process: 31.64Train = 0.000197823\n",
      "Iter 15830 ---- Process: 31.66Train = 0.000105268\n",
      "Iter 15840 ---- Process: 31.68Train = 7.89912e-05\n",
      "Iter 15850 ---- Process: 31.70Train = 7.60279e-05\n",
      "Iter 15860 ---- Process: 31.72Train = 0.000169248\n",
      "Iter 15870 ---- Process: 31.74Train = 6.76621e-05\n",
      "Iter 15880 ---- Process: 31.76Train = 9.63166e-05\n",
      "Iter 15890 ---- Process: 31.78Train = 0.000200046\n",
      "Iter 15900 ---- Process: 31.80Train = 6.31917e-05\n",
      "Iter 15910 ---- Process: 31.82Train = 0.000125235\n",
      "Iter 15920 ---- Process: 31.84Train = 0.000188763\n",
      "Iter 15930 ---- Process: 31.86Train = 0.000127653\n",
      "Iter 15940 ---- Process: 31.88Train = 7.81584e-05\n",
      "Iter 15950 ---- Process: 31.90Train = 0.000381272\n",
      "Iter 15960 ---- Process: 31.92Train = 0.000107505\n",
      "Iter 15970 ---- Process: 31.94Train = 0.000184465\n",
      "Iter 15980 ---- Process: 31.96Train = 0.00032076\n",
      "Iter 15990 ---- Process: 31.98Train = 0.000179368\n",
      "Iter 16000 ---- Process: 32.00Train = 6.85604e-05\n",
      "Iter 16010 ---- Process: 32.02Train = 8.46562e-05\n",
      "Iter 16020 ---- Process: 32.04Train = 6.5755e-05\n",
      "Iter 16030 ---- Process: 32.06Train = 8.16284e-05\n",
      "Iter 16040 ---- Process: 32.08Train = 0.000192065\n",
      "Iter 16050 ---- Process: 32.10Train = 7.67049e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-7acb0363c302>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m#    sess.run(optimizer2,feed_dict={x:X,y:Y,istate:np.zeros((train_batch_size,num_layers*2*n_hidden))})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m#else:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mistate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn_hidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;31m#perform an update on the parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m#cost1 = sess.run(cost,feed_dict = {x:test_x,y:test_y,istate:np.zeros((test_batch_size,num_layers*2*n_hidden))} )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/codefisheng/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    708\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 710\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    711\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/codefisheng/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 908\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    909\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/codefisheng/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    956\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m--> 958\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m    959\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m/home/codefisheng/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m    963\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 965\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/codefisheng/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m    945\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m    946\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m    948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    # Create a summary to monitor cost function\n",
    "    #tf.scalar_summary(\"loss\", cost)\n",
    "    # Merge all summaries to a single operator\n",
    "    #merged_summary_op = tf.merge_all_summaries()\n",
    "\n",
    "    # tensorboard info.# Set logs writer into folder /tmp/tensorflow_logs\n",
    "    #summary_writer = tf.train.SummaryWriter('/tmp/tensorflow_logs', graph_def=sess.graph_def)\n",
    "\n",
    "    #initialize all variables in the model\n",
    "    sess.run(init)\n",
    "    for k in range(num_epoches):\n",
    "        #Generate Data for each epoch\n",
    "        #What this does is it creates a list of of elements of length seq_len, each of size [batch_size,input_size]\n",
    "        #this is required to feed data into rnn.rnn\n",
    "        #print traindays\n",
    "        X,Y = train_data_gen()\n",
    "        X = X.reshape(train_batch_size,n_steps,feature_size)\n",
    "\n",
    "\n",
    "        #Create the dictionary of inputs to feed into sess.run\n",
    "        #if k < 0:\n",
    "        #    sess.run(optimizer2,feed_dict={x:X,y:Y,istate:np.zeros((train_batch_size,num_layers*2*n_hidden))})\n",
    "        #else:\n",
    "        sess.run(optimizer,feed_dict={x:X,y:Y,istate:np.zeros((train_batch_size,num_layers*2*n_hidden))})   \n",
    "        #perform an update on the parameters\n",
    "        #cost1 = sess.run(cost,feed_dict = {x:test_x,y:test_y,istate:np.zeros((test_batch_size,num_layers*2*n_hidden))} )\n",
    "        #print \"Iter \" + str(k) + \", Minibatch Loss ---- Train = \" + str(cost1)\n",
    "        # Write logs at every iteration\n",
    "        #if k>50 & k%10 == 0:\n",
    "        #    summary_str = sess.run(merged_summary_op, feed_dict={x:test_x,y:test_y,istate:np.zeros((test_batch_size,num_layers*2*n_hidden))} )\n",
    "        #    summary_writer.add_summary(summary_str, k)\n",
    "\n",
    "        #if k % 10 == 0:\n",
    "        if k % 10 == 0:\n",
    "            #print test_x\n",
    "            output_tmp_ex,err = sess.run([pred,cost],feed_dict = {x:test_x,y:test_y,istate:np.zeros((test_batch_size,num_layers*2*n_hidden))} )  \n",
    "            print \"Iter \" + str(k) + \" ---- Process: \" + \"{:.2f}\".format(100*float(k)/float(num_epoches)) + \"Train = \" + str(err)\n",
    "            outp_test = output_tmp_ex[:,0]\n",
    "            #print outp_test[0:3]\n",
    "            outlist[kind,:] = outp_test.copy().T\n",
    "            kind = kind + 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RList = np.zeros([(num_epoches/10)])\n",
    "rmseList = np.zeros([(num_epoches/10)])\n",
    "maxeList = np.zeros([(num_epoches/10)])\n",
    "mapeList = np.zeros([(num_epoches/10)])\n",
    "for i in range(kind):\n",
    "    out = np.array(outlist[i])\n",
    "    tmp = out.T.reshape((1,test_batch_size))\n",
    "    RList[i] = np.corrcoef(tmp[0,:],test_y.T[0,:])[0,1]\n",
    "    rmseList[i] = rmse(tmp[0,:],test_y.T[0,:])\n",
    "    maxeList[i] = maxe(tmp[0,:],test_y.T[0,:])\n",
    "    mapeList[i] = mape(tmp[0,:],test_y.T[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = './gefcom-result/INC/'\n",
    "postfix = '-' + str(num_layers) + '-' + str(n_hidden) + '.csv'\n",
    "DataFrame(RList).to_csv(prefix + 'R' + postfix)\n",
    "DataFrame(rmseList).to_csv(prefix + 'RMSE' + postfix)\n",
    "DataFrame(maxeList).to_csv(prefix + 'MAXE' + postfix)\n",
    "DataFrame(mapeList).to_csv(prefix + 'MAPE' + postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = out * 25000\n",
    "test_y = test_y*25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = out.reshape((test_batch_size,1))\n",
    "pred_nd_load = np.concatenate([test_y,out],axis = 1)\n",
    "DataFrame(pred_nd_load).to_csv(prefix + 'pred_nd_load' + postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print np.mean(rmseList[-1001:-1])\n",
    "print np.mean(mapeList[-1001:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time2 = time.time()\n",
    "print time2-time1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
