{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import seq2seq\n",
    "from tensorflow.python.ops import rnn_cell\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sequences(sequence_num, sequence_length, batch_size):\n",
    "    x_data = np.random.uniform(0, 1, size=(sequence_num / batch_size, sequence_length, batch_size, 1))\n",
    "    x_data = np.array(x_data, dtype=np.float32)\n",
    "    #print x_data\n",
    "    y_data = []\n",
    "    for x in x_data:\n",
    "        #print x # first batch\n",
    "        sequence = [x[0]]\n",
    "        #print sequence # first time points of first batch\n",
    "        for index in xrange(1, len(x)):\n",
    "            sequence.append(x[0] * x[index])\n",
    "        # sequence.append([np.max(sequence, axis=0)])\n",
    "        # candidates_for_min = sequence[1:]\n",
    "        # sequence.append([np.min(candidates_for_min, axis=0)])\n",
    "        #print sequence\n",
    "        y_data.append(sequence)\n",
    "\n",
    "    return x_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_seq_of_seq(inputs):\n",
    "    tensor_array = []\n",
    "    for sequence in inputs:\n",
    "        tensor_array.append([tf.constant(x) for x in sequence])\n",
    "\n",
    "    return tensor_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_summaries(var, name):\n",
    "    \"\"\"Attach a lot of summaries to a Tensor.\"\"\"\n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.scalar_summary('mean/' + name, mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_sum(tf.square(var - mean)))\n",
    "        tf.scalar_summary('sttdev/' + name, stddev)\n",
    "        tf.scalar_summary('max/' + name, tf.reduce_max(var))\n",
    "        tf.scalar_summary('min/' + name, tf.reduce_min(var))\n",
    "        tf.histogram_summary(name, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 24, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "datapoints_number = 1000\n",
    "sequence_size = 24\n",
    "batch_size = 10\n",
    "data_point_dim = 1\n",
    "\n",
    "if datapoints_number % float(batch_size) != 0:\n",
    "    raise ValueError('Number of samples must be divisible with batch size')\n",
    "\n",
    "inputs, outputs = generate_sequences(sequence_num=datapoints_number, sequence_length=sequence_size,\n",
    "                                     batch_size=batch_size)\n",
    "\n",
    "print inputs.shape\n",
    "input_dim = len(inputs[0]) # batch_size\n",
    "output_dim = len(outputs[0])\n",
    "\n",
    "encoder_inputs = [tf.placeholder(tf.float32, shape=[batch_size, data_point_dim]) for _ in xrange(input_dim)]\n",
    "\n",
    "decoder_inputs = [tf.placeholder(tf.float32, shape=[batch_size, data_point_dim]) for _ in xrange(output_dim)]\n",
    "\n",
    "model_outputs, states = seq2seq.basic_rnn_seq2seq(encoder_inputs,\n",
    "                                                  decoder_inputs,\n",
    "                                                  rnn_cell.BasicLSTMCell(data_point_dim, state_is_tuple=True))\n",
    "\n",
    "reshaped_outputs = tf.reshape(model_outputs, [-1])\n",
    "reshaped_results = tf.reshape(decoder_inputs, [-1])\n",
    "\n",
    "cost = tf.reduce_sum(tf.squared_difference(reshaped_outputs, reshaped_results))\n",
    "variable_summaries(cost, 'cost')\n",
    "\n",
    "step = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "merged = tf.merge_all_summaries()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    # writer = tf.train.SummaryWriter(\"/tmp/tensor/train\", session.graph, )\n",
    "\n",
    "    costs = []\n",
    "    n_iterations = 100\n",
    "    for i in xrange(n_iterations):\n",
    "        batch_costs = []\n",
    "        summary = None\n",
    "\n",
    "        for batch_inputs, batch_outputs in zip(inputs, outputs):\n",
    "            x_list = {key: value for (key, value) in zip(encoder_inputs, batch_inputs)}\n",
    "            y_list = {key: value for (key, value) in zip(decoder_inputs, batch_outputs)}\n",
    "\n",
    "            summary, err, _ = session.run([merged, cost, step], feed_dict=dict(x_list.items() + y_list.items()))\n",
    "            batch_costs.append(err)\n",
    "        # if summary is not None:\n",
    "        #     writer.add_summary(summary, i)\n",
    "        costs.append(np.average(batch_costs, axis=0))\n",
    "\n",
    "plt.plot(costs)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function zip in module __builtin__:\n",
      "\n",
      "zip(...)\n",
      "    zip(seq1 [, seq2 [...]]) -> [(seq1[0], seq2[0] ...), (...)]\n",
      "    \n",
      "    Return a list of tuples, where each tuple contains the i-th element\n",
      "    from each of the argument sequences.  The returned list is truncated\n",
      "    in length to the length of the shortest argument sequence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help (zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n",
      "(24, 10, 1)\n"
     ]
    }
   ],
   "source": [
    "datapoints_number = 1000\n",
    "sequence_size = 24\n",
    "batch_size = 10\n",
    "data_point_dim = 1\n",
    "\n",
    "if datapoints_number % float(batch_size) != 0:\n",
    "    raise ValueError('Number of samples must be divisible with batch size')\n",
    "\n",
    "inputs, outputs = generate_sequences(sequence_num=datapoints_number, sequence_length=sequence_size,\n",
    "                                     batch_size=batch_size)\n",
    "for batch_inputs, batch_outputs in zip(inputs, outputs):\n",
    "    print batch_inputs.shape\n",
    "    x_list = {key: value for (key, value) in zip(encoder_inputs, batch_inputs)}\n",
    "    y_list = {key: value for (key, value) in zip(decoder_inputs, batch_outputs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
